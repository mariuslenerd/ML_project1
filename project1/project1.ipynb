{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87e6083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e42811",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "x_train_raw, x_test_raw,y_train, train_ids, test_ids = load_csv_data('/Users/mpecaut/Documents/EPFL/MASTER/MA3/ML/projects/project1/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88380452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat y_train to have 0's instead of -1's\n",
    "y_train_original = y_train.copy()\n",
    "y_train[y_train == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f793521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 321)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace NaN by a float to treat NaN as a categorical feature\n",
    "x_test_raw = np.nan_to_num(x_train_raw, nan = -10.0)\n",
    "x_test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a1a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.911697929205967\n",
      "0.08830207079403295\n",
      "328135\n"
     ]
    }
   ],
   "source": [
    "#look at ratio of heart attack/no heart attack in y\n",
    "print(len(y_train[y_train == 0])/len(y_train))\n",
    "print(len(y_train[y_train==1])/len(y_train))\n",
    "print(len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36423f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 12,\n",
       " 3: 12,\n",
       " 5: 2,\n",
       " 6: 2,\n",
       " 9: 2,\n",
       " 10: 3,\n",
       " 11: 2,\n",
       " 12: 2,\n",
       " 13: 3,\n",
       " 14: 3,\n",
       " 15: 17,\n",
       " 16: 13,\n",
       " 17: 12,\n",
       " 18: 2,\n",
       " 19: 2,\n",
       " 20: 3,\n",
       " 21: 3,\n",
       " 22: 2,\n",
       " 23: 3,\n",
       " 24: 5,\n",
       " 26: 8,\n",
       " 30: 4,\n",
       " 31: 5,\n",
       " 32: 5,\n",
       " 33: 8,\n",
       " 34: 7,\n",
       " 35: 5,\n",
       " 36: 4,\n",
       " 37: 7,\n",
       " 38: 5,\n",
       " 39: 4,\n",
       " 40: 4,\n",
       " 41: 5,\n",
       " 42: 5,\n",
       " 43: 4,\n",
       " 44: 4,\n",
       " 45: 5,\n",
       " 46: 4,\n",
       " 47: 4,\n",
       " 48: 7,\n",
       " 50: 2,\n",
       " 51: 7,\n",
       " 52: 7,\n",
       " 53: 5,\n",
       " 54: 5,\n",
       " 55: 9,\n",
       " 56: 5,\n",
       " 57: 5,\n",
       " 58: 9,\n",
       " 60: 11,\n",
       " 61: 5,\n",
       " 64: 5,\n",
       " 65: 5,\n",
       " 66: 5,\n",
       " 67: 5,\n",
       " 68: 5,\n",
       " 69: 5,\n",
       " 70: 5,\n",
       " 71: 5,\n",
       " 72: 5,\n",
       " 73: 6,\n",
       " 74: 5,\n",
       " 75: 11,\n",
       " 76: 6,\n",
       " 87: 5,\n",
       " 95: 5,\n",
       " 96: 5,\n",
       " 97: 6,\n",
       " 98: 14,\n",
       " 99: 9,\n",
       " 100: 5,\n",
       " 102: 14,\n",
       " 103: 5,\n",
       " 104: 5,\n",
       " 106: 12,\n",
       " 107: 5,\n",
       " 108: 6,\n",
       " 109: 4,\n",
       " 115: 8,\n",
       " 116: 5,\n",
       " 117: 5,\n",
       " 118: 6,\n",
       " 119: 18,\n",
       " 120: 8,\n",
       " 121: 7,\n",
       " 122: 16,\n",
       " 123: 5,\n",
       " 124: 5,\n",
       " 125: 9,\n",
       " 126: 5,\n",
       " 127: 9,\n",
       " 128: 8,\n",
       " 129: 8,\n",
       " 130: 11,\n",
       " 131: 9,\n",
       " 132: 5,\n",
       " 133: 5,\n",
       " 134: 4,\n",
       " 135: 4,\n",
       " 136: 5,\n",
       " 137: 8,\n",
       " 138: 8,\n",
       " 139: 8,\n",
       " 140: 8,\n",
       " 141: 5,\n",
       " 142: 5,\n",
       " 144: 5,\n",
       " 146: 4,\n",
       " 147: 9,\n",
       " 148: 12,\n",
       " 149: 19,\n",
       " 151: 9,\n",
       " 152: 8,\n",
       " 153: 7,\n",
       " 154: 10,\n",
       " 155: 5,\n",
       " 156: 5,\n",
       " 157: 5,\n",
       " 158: 6,\n",
       " 159: 5,\n",
       " 160: 4,\n",
       " 161: 5,\n",
       " 162: 7,\n",
       " 163: 5,\n",
       " 164: 5,\n",
       " 165: 5,\n",
       " 166: 7,\n",
       " 167: 6,\n",
       " 168: 6,\n",
       " 169: 5,\n",
       " 170: 5,\n",
       " 171: 8,\n",
       " 172: 5,\n",
       " 173: 8,\n",
       " 174: 5,\n",
       " 175: 8,\n",
       " 176: 5,\n",
       " 177: 5,\n",
       " 178: 8,\n",
       " 179: 5,\n",
       " 180: 8,\n",
       " 181: 5,\n",
       " 182: 5,\n",
       " 183: 9,\n",
       " 184: 5,\n",
       " 185: 5,\n",
       " 186: 5,\n",
       " 187: 5,\n",
       " 188: 8,\n",
       " 189: 8,\n",
       " 190: 6,\n",
       " 191: 9,\n",
       " 192: 9,\n",
       " 193: 9,\n",
       " 194: 7,\n",
       " 196: 7,\n",
       " 198: 7,\n",
       " 199: 7,\n",
       " 200: 4,\n",
       " 201: 9,\n",
       " 202: 5,\n",
       " 203: 5,\n",
       " 204: 8,\n",
       " 205: 7,\n",
       " 206: 18,\n",
       " 207: 18,\n",
       " 208: 18,\n",
       " 209: 18,\n",
       " 210: 18,\n",
       " 211: 18,\n",
       " 212: 18,\n",
       " 213: 18,\n",
       " 214: 5,\n",
       " 215: 5,\n",
       " 216: 8,\n",
       " 217: 4,\n",
       " 218: 5,\n",
       " 221: 12,\n",
       " 223: 4,\n",
       " 224: 10,\n",
       " 225: 10,\n",
       " 227: 3,\n",
       " 230: 3,\n",
       " 231: 3,\n",
       " 232: 3,\n",
       " 233: 4,\n",
       " 234: 4,\n",
       " 235: 3,\n",
       " 236: 3,\n",
       " 237: 4,\n",
       " 238: 3,\n",
       " 239: 10,\n",
       " 240: 9,\n",
       " 241: 3,\n",
       " 242: 9,\n",
       " 243: 3,\n",
       " 244: 6,\n",
       " 245: 6,\n",
       " 246: 14,\n",
       " 247: 3,\n",
       " 249: 6,\n",
       " 254: 5,\n",
       " 255: 3,\n",
       " 256: 7,\n",
       " 257: 5,\n",
       " 258: 6,\n",
       " 259: 5,\n",
       " 260: 3,\n",
       " 261: 4,\n",
       " 263: 3,\n",
       " 265: 3,\n",
       " 272: 3,\n",
       " 273: 5,\n",
       " 274: 2,\n",
       " 275: 2,\n",
       " 278: 3,\n",
       " 279: 3,\n",
       " 280: 2,\n",
       " 281: 2,\n",
       " 282: 3,\n",
       " 283: 3,\n",
       " 284: 3,\n",
       " 289: 4,\n",
       " 290: 4,\n",
       " 298: 3,\n",
       " 305: 5,\n",
       " 306: 3,\n",
       " 307: 4,\n",
       " 308: 4,\n",
       " 309: 3,\n",
       " 310: 3,\n",
       " 311: 5,\n",
       " 312: 3,\n",
       " 313: 5,\n",
       " 314: 5,\n",
       " 315: 6,\n",
       " 316: 3,\n",
       " 317: 3,\n",
       " 318: 4,\n",
       " 319: 4,\n",
       " 320: 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 53,\n",
       " 2: 414,\n",
       " 4: 31,\n",
       " 7: 21780,\n",
       " 8: 21780,\n",
       " 25: 26,\n",
       " 27: 34,\n",
       " 28: 33,\n",
       " 29: 34,\n",
       " 49: 99,\n",
       " 59: 26,\n",
       " 62: 551,\n",
       " 63: 143,\n",
       " 77: 41,\n",
       " 78: 49,\n",
       " 79: 44,\n",
       " 80: 59,\n",
       " 81: 110,\n",
       " 82: 135,\n",
       " 83: 109,\n",
       " 84: 116,\n",
       " 85: 104,\n",
       " 86: 134,\n",
       " 88: 78,\n",
       " 89: 116,\n",
       " 90: 195,\n",
       " 91: 79,\n",
       " 92: 100,\n",
       " 93: 169,\n",
       " 94: 102,\n",
       " 101: 29,\n",
       " 105: 413,\n",
       " 110: 80,\n",
       " 111: 73,\n",
       " 112: 48,\n",
       " 113: 42,\n",
       " 114: 46,\n",
       " 143: 137,\n",
       " 145: 73,\n",
       " 150: 26,\n",
       " 195: 94,\n",
       " 197: 93,\n",
       " 219: 1306,\n",
       " 220: 1305,\n",
       " 222: 5528,\n",
       " 226: 20453,\n",
       " 228: 107,\n",
       " 229: 216913,\n",
       " 248: 63,\n",
       " 250: 53,\n",
       " 251: 104,\n",
       " 252: 542,\n",
       " 253: 3525,\n",
       " 262: 36,\n",
       " 264: 237,\n",
       " 266: 98,\n",
       " 267: 122,\n",
       " 268: 97,\n",
       " 269: 103,\n",
       " 270: 93,\n",
       " 271: 118,\n",
       " 276: 501,\n",
       " 277: 1025,\n",
       " 285: 30,\n",
       " 286: 30,\n",
       " 287: 163,\n",
       " 288: 156,\n",
       " 291: 193,\n",
       " 292: 167,\n",
       " 293: 111,\n",
       " 294: 95,\n",
       " 295: 730,\n",
       " 296: 577,\n",
       " 297: 97,\n",
       " 299: 858,\n",
       " 300: 673,\n",
       " 301: 2667,\n",
       " 302: 535,\n",
       " 303: 416,\n",
       " 304: 1374}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = x_train_raw.shape[1]\n",
    "numerical_idx = {}\n",
    "categorical_idx = {}\n",
    "for feature in range(num_features) : \n",
    "    full_column = x_train_raw[:,feature]\n",
    "    nb_unique_vals = len(np.unique(full_column))\n",
    "    if nb_unique_vals < 20 : \n",
    "        categorical_idx[feature] = nb_unique_vals\n",
    "    else : \n",
    "        numerical_idx[feature] = nb_unique_vals\n",
    "\n",
    "display(categorical_idx)\n",
    "display(numerical_idx)\n",
    "\n",
    "#to test my one hot encode, i use feature 1 on following cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d81aae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1.0: 0,\n",
       " 2.0: 1,\n",
       " 3.0: 2,\n",
       " 4.0: 3,\n",
       " 5.0: 4,\n",
       " 6.0: 5,\n",
       " 7.0: 6,\n",
       " 8.0: 7,\n",
       " 9.0: 8,\n",
       " 10.0: 9,\n",
       " 11.0: 10,\n",
       " 12.0: 11}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(328135, 12))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_one_hot_encode = x_train_raw[:,1]\n",
    "unique_vals = np.unique(x_train_one_hot_encode)\n",
    "print(np.unique(x_train_one_hot_encode)) #my array has value from 1 to 12 : 12 categories -> want to create Nx12 matrix filled up with 0 except for when sample N belong to category i : filled with 1 \n",
    "#create maping : \n",
    "mapping = {float(val) : i for i,val in enumerate(unique_vals)}\n",
    "display(mapping)\n",
    "x_mapped =  np.array([mapping[v] for v in x_train_one_hot_encode])\n",
    "x_encoded = np.eye(len(unique_vals))[x_mapped]\n",
    "\n",
    "display(x_encoded)\n",
    "#x_train_encoded = np.eye(len(np.unique(x_train_one_hot_encode)))[x_train_one_hot_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_idx, categorical_idx = find_categorical(x_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54807cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11. 12. 10. ... 10. 12.  9.]\n",
      "[11. 12. 10. ... 10. 12.  9.]\n",
      "[2015. 2015. 2015. ... 2015. 2015. 2015.]\n",
      "[1100. 1200. 1100. ... 1100. 1100. 1100.]\n",
      "[nan  1.  1. ...  1.  1.  1.]\n",
      "[nan  1.  1. ...  1.  1.  1.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan  1.  1. ...  1.  1.  1.]\n",
      "[nan  1.  2. ...  1.  1.  2.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan  2.  2. ...  1.  3.  2.]\n",
      "[nan  1.  1. ...  0.  2.  1.]\n",
      "[nan  1.  1. ...  1.  1.  1.]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[ 2. nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[2. 4. 2. ... 3. 3. 2.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 2.]\n",
      "[2. 2. 2. ... 2. 2. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[3. 1. 3. ... 3. 3. 1.]\n",
      "[nan  1. nan ... nan nan  2.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[2. 2. 1. ... 1. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[2. 2. 2. ... 2. 1. 2.]\n",
      "[nan nan nan ... nan  1. nan]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[2. 2. 1. ... 2. 2. 1.]\n",
      "[1. 2. 2. ... 1. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[3. 3. 3. ... 3. 3. 3.]\n",
      "[2. 1. 2. ... 2. 1. 2.]\n",
      "[1. 1. 1. ... 3. 1. 1.]\n",
      "[5. 4. 6. ... 5. 4. 6.]\n",
      "[1. 1. 1. ... 2. 1. 1.]\n",
      "[nan  2.  2. ...  2.  2.  2.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan  1.  1. ...  1.  1.  1.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[1. 1. 1. ... 7. 1. 1.]\n",
      "[ 8.  7. 99. ...  3.  8.  8.]\n",
      "[1. 2. 1. ... 2. 1. 1.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[1. 2. 2. ... 1. 2. 2.]\n",
      "[2. 2. 2. ... 1. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[2. 1. 2. ... 2. 2. 2.]\n",
      "[2. 2. 2. ... 1. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[1. 1. 1. ... 2. 2. 2.]\n",
      "[ 1.  1.  3. ... nan nan nan]\n",
      "[ 1.  2. nan ... nan nan nan]\n",
      "[nan nan  7. ... nan nan nan]\n",
      "[3. 3. 3. ... 3. 3. 3.]\n",
      "[ 1. nan  1. ...  1.  1.  1.]\n",
      "[nan nan  2. ... nan nan  2.]\n",
      "[nan nan  2. ... nan nan  2.]\n",
      "[nan nan  3. ... nan nan  3.]\n",
      "[nan nan  5. ... nan nan  5.]\n",
      "[ 1. nan  1. ...  2.  1.  1.]\n",
      "[ 1. nan  1. ...  2.  1.  2.]\n",
      "[ 8. nan  5. ... nan  1. nan]\n",
      "[ 2. nan  2. ...  2.  2.  2.]\n",
      "[ 2. nan  2. ...  2.  2.  2.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ...  1. nan nan]\n",
      "[nan nan nan ...  3. nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ...  2. nan  2.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[ 3. nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[ 5. nan nan ... nan nan nan]\n",
      "[ 2. nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan  2.]\n",
      "[ 4. nan nan ... nan nan nan]\n",
      "[ 1. nan nan ... nan nan  2.]\n",
      "[ 2. nan nan ... nan nan nan]\n",
      "[ 4. nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan  1. ...  1. nan  1.]\n",
      "[nan nan  4. ...  4. nan  4.]\n",
      "[nan nan nan ... nan nan  1.]\n",
      "[nan nan nan ... nan nan  1.]\n",
      "[nan nan nan ... nan nan  2.]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[20. 10. 11. ... 11. 10. 10.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[nan  5.  1. ...  1.  5.  1.]\n",
      "[1. 2. 2. ... 1. 3. 2.]\n",
      "[nan  9.  9. ...  9.  9.  1.]\n",
      "[nan nan nan ... nan nan  6.]\n",
      "[nan nan nan ... nan nan  6.]\n",
      "[2. 1. 1. ... 1. 1. 1.]\n",
      "[1. 2. 1. ... 1. 1. 1.]\n",
      "[1. 1. 9. ... 9. 1. 1.]\n",
      "[1. 2. 1. ... 1. 1. 2.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 2. ... 2. 1. 1.]\n",
      "[1. 1. 1. ... 1. 2. 1.]\n",
      "[1. 1. 1. ... 1. 2. 1.]\n",
      "[3. 3. 3. ... 3. 1. 3.]\n",
      "[2. 2. 1. ... 2. 2. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[2. 2. 2. ... 2. 2. 2.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[ 8.  8. 10. ... 10.  5.  7.]\n",
      "[1. 1. 2. ... 2. 1. 1.]\n",
      "[5. 5. 6. ... 6. 3. 4.]\n",
      "[ 2.  3. nan ...  4.  4.  2.]\n",
      "[1. 2. 9. ... 2. 2. 1.]\n",
      "[1. 1. 1. ... 1. 1. 2.]\n",
      "[3. 2. 4. ... 3. 2. 4.]\n",
      "[5. 5. 9. ... 2. 5. 5.]\n",
      "[1. 1. 3. ... 4. 4. 4.]\n",
      "[2. 2. 1. ... 1. 1. 1.]\n",
      "[2. 1. 1. ... 2. 2. 2.]\n",
      "[1. 9. 1. ... 1. 1. 1.]\n",
      "[1. 9. 1. ... 1. 1. 1.]\n",
      "[0. 2. 0. ... 0. 0. 0.]\n",
      "[0. 4. 0. ... 0. 0. 0.]\n",
      "[1. 0. 1. ... 1. 1. 1.]\n",
      "[1. 0. 1. ... 1. 1. 1.]\n",
      "[2. 9. 1. ... 1. 2. 1.]\n",
      "[1. 9. 1. ... 2. 2. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[1. 9. 1. ... 1. 1. 1.]\n",
      "[ 1. nan  1. ...  1.  2.  1.]\n",
      "[ 1. nan  0. ...  0.  0.  0.]\n",
      "[0. 9. 0. ... 0. 0. 1.]\n",
      "[2. 9. 3. ... 3. 3. 9.]\n",
      "[1. 9. 2. ... 2. 2. 9.]\n",
      "[1. 9. 2. ... 2. 2. 9.]\n",
      "[2. 9. 2. ... 2. 2. 9.]\n",
      "[2. 9. 2. ... 2. 2. 9.]\n",
      "[1. 9. 2. ... 1. 1. 1.]\n",
      "[1. 9. 4. ... 3. 3. 9.]\n",
      "[1. 9. 2. ... 2. 2. 9.]\n",
      "[3. 3. 2. ... 3. 3. 2.]\n",
      "[3. 3. 2. ... 3. 3. 2.]\n",
      "[4. 4. 3. ... 4. 4. 3.]\n",
      "[1. 9. 1. ... 1. 1. 1.]\n",
      "[1. 9. 1. ... 2. 1. 1.]\n",
      "[nan nan  1. ...  2. nan nan]\n",
      "[nan nan  2. ...  2. nan nan]\n",
      "[ 2. nan  2. ...  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "for i in categorical_idx: \n",
    "    x = x_train_raw[:,i]\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0673a59",
   "metadata": {},
   "source": [
    "### Malamud function for OLS - just did copy past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6da1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ols_matrix(X, y):\n",
    "    \"\"\"Perform OLS regression using matrix inversion.\"\"\"\n",
    "    X_mat = np.column_stack((np.ones(len(X)), X))  # Add intercept term\n",
    "    beta = np.linalg.pinv(X_mat.T @ X_mat) @ X_mat.T @ y  # OLS formula: (X'X)^-1 X'Y\n",
    "    y_pred = X_mat @ beta  # Predicted values\n",
    "\n",
    "    # Compute residuals\n",
    "    residuals = y - y_pred\n",
    "    n, k = X_mat.shape\n",
    "\n",
    "    # Compute residual variance\n",
    "    residual_var = np.sum(residuals**2) / (n - k)\n",
    "\n",
    "    # Compute standard errors\n",
    "    XTX_inv = np.linalg.inv(X_mat.T @ X_mat)\n",
    "    std_errors = np.sqrt(np.diag(residual_var * XTX_inv))\n",
    "\n",
    "    # Compute t-statistics\n",
    "    t_stats = beta / std_errors\n",
    "\n",
    "   \n",
    "\n",
    "    return {\n",
    "        'Intercept': beta[0],\n",
    "        'Coefficient': beta[1],\n",
    "        'Std Error (Coef)': std_errors[1],\n",
    "        'T-Statistic (Coef)': t_stats[1],\n",
    "        'T-Statistic (Intercept)': t_stats[0]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a45595",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ols_reg \u001b[38;5;241m=\u001b[39m \u001b[43mols_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mols_matrix\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform OLS regression using matrix inversion.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m X_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack((np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(X)), X))  \u001b[38;5;66;03m# Add intercept term\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_mat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_mat\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m X_mat\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m y  \u001b[38;5;66;03m# OLS formula: (X'X)^-1 X'Y\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m X_mat \u001b[38;5;241m@\u001b[39m beta  \u001b[38;5;66;03m# Predicted values\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Compute residuals\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/empiricalmethods/lib/python3.13/site-packages/numpy/linalg/_linalg.py:2231\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian, rtol)\u001b[0m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap(res)\n\u001b[1;32m   2230\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m-> 2231\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhermitian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhermitian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;66;03m# discard small singular values\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m rcond[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, newaxis] \u001b[38;5;241m*\u001b[39m amax(s, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/empiricalmethods/lib/python3.13/site-packages/numpy/linalg/_linalg.py:1812\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1808\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_svd_nonconvergence,\n\u001b[1;32m   1810\u001b[0m               invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1811\u001b[0m               under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1812\u001b[0m     u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1814\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/empiricalmethods/lib/python3.13/site-packages/numpy/linalg/_linalg.py:113\u001b[0m, in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_raise_linalgerror_svd_nonconvergence\u001b[39m(err, flag):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "ols_reg = ols_matrix(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfabcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empiricalmethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
