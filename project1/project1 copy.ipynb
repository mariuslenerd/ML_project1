{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "87e6083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'implemented_functions' from '/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import data_preprocessing\n",
    "import importlib\n",
    "importlib.reload(data_preprocessing)\n",
    "import cross_validation\n",
    "import TEST\n",
    "importlib.reload(TEST)\n",
    "importlib.reload(cross_validation)\n",
    "import implemented_functions\n",
    "importlib.reload(implemented_functions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0e42811",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c76a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "x_train_raw, x_test_raw,y_train_raw, train_ids, test_ids = load_csv_data('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9001d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n",
      "(109379, 321)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(x_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0f96d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3000000e+01, 1.1000000e+01, 1.1162015e+07, ...,           nan,\n",
       "                  nan, 2.0000000e+00],\n",
       "       [3.3000000e+01, 1.2000000e+01, 1.2152015e+07, ...,           nan,\n",
       "                  nan,           nan],\n",
       "       [2.0000000e+01, 1.0000000e+01, 1.0202015e+07, ..., 1.0000000e+00,\n",
       "        2.0000000e+00, 2.0000000e+00],\n",
       "       ...,\n",
       "       [3.9000000e+01, 1.0000000e+01, 1.0202015e+07, ..., 2.0000000e+00,\n",
       "        2.0000000e+00, 2.0000000e+00],\n",
       "       [3.3000000e+01, 1.2000000e+01, 1.2302015e+07, ...,           nan,\n",
       "                  nan, 2.0000000e+00],\n",
       "       [3.2000000e+01, 9.0000000e+00, 9.1220150e+06, ...,           nan,\n",
       "                  nan, 2.0000000e+00]], shape=(328135, 321))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88380452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat y_train to have 0's instead of -1's\n",
    "y_train_original = y_train_raw.copy()\n",
    "y_train_raw[y_train_raw == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f793521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.4000000e+01,  2.0000000e+00,  2.0820150e+06, ...,\n",
       "         1.0000000e+00,  1.0000000e+00,  2.0000000e+00],\n",
       "       [ 2.7000000e+01,  1.0000000e+00,  1.1920150e+06, ...,\n",
       "        -1.0000000e+01, -1.0000000e+01,  2.0000000e+00],\n",
       "       [ 3.5000000e+01,  5.0000000e+00,  5.2620150e+06, ...,\n",
       "         1.0000000e+00,  1.0000000e+00,  2.0000000e+00],\n",
       "       ...,\n",
       "       [ 9.0000000e+00,  1.1000000e+01,  1.1272015e+07, ...,\n",
       "         9.0000000e+00,  9.0000000e+00, -1.0000000e+01],\n",
       "       [ 1.5000000e+01,  1.2000000e+01,  1.2122015e+07, ...,\n",
       "         1.0000000e+00,  1.0000000e+00,  2.0000000e+00],\n",
       "       [ 4.5000000e+01,  1.2000000e+01,  1.2282015e+07, ...,\n",
       "        -1.0000000e+01, -1.0000000e+01,  2.0000000e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace NaN by a float to treat NaN as a categorical feature\n",
    "#TODO: NAN'S :apagnan -10 or 0 --> SAME BETWEEN TRAIN AND TEST \n",
    "x_test_raw = np.nan_to_num(x_test_raw, nan = -10.0)\n",
    "x_test_raw.shape\n",
    "x_test_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75961310",
   "metadata": {},
   "source": [
    "### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1db0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annoted = data_preprocessing.read_annotated_csv('dataset/data_anotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc22ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = data_preprocessing.preprocess_data2(x_train_raw[:,:], y_train_raw[:], x_test_raw[:,:], data_annoted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03843053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaed223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\\nx_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\n",
    "x_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\\ndata_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\n",
    "data_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14361aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('x_train_preprocessed.csv', x_train, delimiter=',')\n",
    "np.savetxt('y_train_preprocessed.csv', y_train, delimiter=',')\n",
    "np.savetxt('x_test_preprocessed.csv', x_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ec040d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "404fcaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288135, 202)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "902e07c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 202)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfff5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:140: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(tx,y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: Loss = 0.0332660697950054\n",
      "Mean Squared Error SGD (gamma=0.01): Loss = [0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.0749258961124294, 0.054024583237476595, 0.04480624930402055, 0.04293347013949835, 0.04099149109216073, 0.04099936986926757, 0.042989632041564814, 0.044101282974364206, 0.04402058585745735, 0.046572555850146406, 0.045108203458412585, 0.04407016446199036, 0.04497490727528111, 0.04509829944583116, 0.0444487991714604, 0.04468083061976731, 0.044184175379590754, 0.047599225181837714, 0.046456071460284645, 0.04411796906478281, 0.043951025769181244, 0.04497369517638807, 0.04364201950361575, 0.043832719700901, 0.04325802603117721, 0.044659856709434335, 0.043913089904173835, 0.04416968698738487, 0.044588666324743544, 0.04396520139722135, 0.044863963891160194, 0.04445744811067444, 0.05317428300556608, 0.04214131538943833, 0.09233016679175486, 0.06112889542469105, 0.0490558958588751, 0.04481144924326513, 0.07936527083122706, 0.05674774230078387, 0.042837402261028855, 0.04191574874197226, 0.07135087778761093, 0.06070762241388062]\n",
      "Mean Squared Error SGD (gamma=0.1): Loss = [0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 4.648598056482129, 28.822757857392922, 234.11914551979538, 2058.9802462026714, 10754.98167369858, 73518.77591053436, 315581.6058316376, 821685.8075395782, 8394828.923953805, 5367629.048149675, 37866596.38486694, 94405686.85624987, 1148324720.9498096, 7729619737.792355, 23933174191.23809, 61761289197.70298, 18071840824.47112, 226506001602.86316, 890416212383.9725, 8528094817442.098, 1296189929293.0508, 27229448049397.977, 37858639862231.41, 409341565051880.0, 2489851156157658.5, 1.4187507289629944e+16, 1.5600807198189677e+17, 1.181138803388448e+18, 6.831093515149929e+18, 3.0219769794197553e+19, 9.19993433109278e+19, 3.965290723118636e+20, 9.746758713723256e+20, 8.418006041514209e+21, 6.8971092593567666e+22, 4.387886654040688e+22, 4.955294329727337e+22, 1.6435301883781616e+23, 5.133894297149491e+23, 6.506918520516066e+23, 5.674561865061116e+24, 5.168792102561895e+25, 4.551710500037237e+26, 2.6641075704792303e+27, 1.0818360922659774e+28]\n",
      "Mean Squared Error SGD (gamma=0.5): Loss = [0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 119.38953952008184, 5018.796175732374, 914087.4837431516, 209945362.74868658, 39008642708.36196, 11758518263859.527, 1039662752215396.8, 3.0396773341036045e+17, 5.289823155814673e+19, 1.3778617509289314e+22, 4.4775532943284527e+24, 1.200943370754017e+27, 2.9146212307609065e+29, 5.735402431607778e+31, 1.0543596265283402e+34, 2.3093337863792763e+35, 5.29368602784805e+37, 1.7309920852307393e+40, 5.654827517593198e+41, 7.790385324155254e+43, 2.7481041624075917e+46, 6.182801229599179e+48, 7.853553025387314e+50, 1.2222825618617806e+53, 2.9638094289999273e+55, 9.572785772432842e+57, 3.129500226730012e+59, 6.600274557497445e+61, 7.824474596329156e+63, 1.5423195460770102e+66, 5.414551429135175e+68, 1.0488273838967e+71, 2.2515513337462115e+73, 4.832305937019761e+75, 1.0861420809021623e+78, 9.829097652548177e+79, 2.0429460757077327e+82]\n",
      "Mean Squared Error SGD (gamma=1): Loss = [0.04412341437173547, 0.04412341437173547, 0.04412341437173547, 375.3722617015025, 333607.2132930617, 434625222.10089964, 603986833521.8284, 699922773899370.0, 8.49632740984961e+17, 1.367155960330347e+21, 1.5211031977450142e+24, 2.0283574872450444e+27, 1.839125545257475e+30, 1.0491346655325174e+33, 9.240599214653399e+35, 4.464244679866295e+38, 5.493080471346008e+41, 6.714188177989538e+44, 5.499883043560544e+47, 4.640171676203108e+50, 1.8290868895242729e+53, 1.8827701609817409e+56, 1.6140353069882025e+59, 1.5275912581192105e+62, 2.6678760529749164e+65, 2.955544732720011e+68, 4.177368451615692e+71, 3.072813584871483e+74, 7.189183043966407e+76, 3.0215439143131145e+79, 2.5595221160396157e+81, 4.06089080336139e+84, 4.7886172616526355e+87, 3.4644363593938766e+90, 4.727176417777792e+93, 3.251731644752535e+96, 2.4338222813452356e+99, 1.3121485241977263e+102, 5.2809486738204696e+104, 3.227094326276907e+107, 3.117922823527533e+110, 2.88169098292202e+113, 2.4000418814381295e+116, 3.9392651548046313e+118, 5.082804127435189e+121, 6.583555339197676e+124, 7.594585091550096e+127, 1.1507381756597708e+131, 1.1404874947961362e+134, 1.2212232585957796e+137]\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.1): Loss = 0.14587802645055686\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.01): Loss = 0.029461618507182766\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.1): Loss = 0.18040077556862305\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.01): Loss = 0.03304224170546889\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.1): Loss = 0.7490641943619778\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.01): Loss = 0.03739012610923561\n",
      "Ridge Regression (alpha=0.001): Loss = 0.07832770443530372\n",
      "Ridge Regression (alpha=0.01): Loss = 0.07974956448070161\n",
      "Ridge Regression (alpha=0.1): Loss = 0.08400252140436557\n",
      "Ridge Regression (alpha=1): Loss = 0.1022724079722026\n",
      "Ridge Regression (alpha=10): Loss = 0.15235576492530228\n",
      "Logistic Regression: Loss = 1.0296163642046903\n",
      "Logistic Regression: Loss = 1.009490609909541\n",
      "Logistic Regression: Loss = 0.9288256895630238\n",
      "Logistic Regression: Loss = 0.89438592091819\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.01): Loss = 7.273041593297525e-05\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.01): Loss = 0.0006606929310288802\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.01): Loss = 0.0063198390527552184\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.1): Loss = 0.00020061453342858952\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.1): Loss = 0.0018905517506785524\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.1): Loss = 0.014721403017462293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_w = np.zeros(x_train.shape[1])\n",
    "max_iters = 50\n",
    "\n",
    "x_test = x_train[-40000:,:]\n",
    "y_test = y_train[-40000:]\n",
    "x_train = x_train[:-40000,:]\n",
    "y_train = y_train[:-40000]\n",
    "\n",
    "\n",
    "w_least_squares, loss_ls = implemented_functions.least_squares(y_train, x_train)\n",
    "print(f\"Least Squares: Loss = {loss_ls}\")\n",
    "\n",
    "best_mse_coef = 0\n",
    "best_mse_loss = np.inf\n",
    "best_mse_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_sgd, loss_sgd = implemented_functions.mean_squared_error_sgd(y_train,  x_train, initial_w, max_iters, gamma)\n",
    "    if loss_sgd[-1] < best_mse_loss:\n",
    "        best_mse_loss = loss_sgd[-1]\n",
    "        best_mse_coef = gamma\n",
    "        best_mse_weights = w_sgd\n",
    "    print(f\"Mean Squared Error SGD (gamma={gamma}): Loss = {loss_sgd}\")\n",
    "\n",
    "best_log_lasso_coef = 0\n",
    "best_log_lasso_loss = np.inf\n",
    "best_log_lasso_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5]:\n",
    "    for lambda_ in [0.1, 0.01]:\n",
    "        w_log_lasso, loss_log_lasso = implemented_functions.reg_logistic_lasso_subgradient(y_train, x_train, lambda_, initial_w, max_iters, gamma)\n",
    "        if loss_log_lasso < best_log_lasso_loss:\n",
    "            best_log_lasso_loss = loss_log_lasso\n",
    "            best_log_lasso_weights = w_log_lasso\n",
    "        print(f\"Regularized Lasso Logistic Regression (gamma={gamma}, lambda={lambda_}): Loss = {loss_log_lasso}\")\n",
    "        \n",
    "best_ridge_coef = 0\n",
    "best_ridge_loss = np.inf\n",
    "best_ridge_weights = None\n",
    "for ridge_coef in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    w_ridge, loss_ridge = implemented_functions.ridge_regression(y_train, x_train, ridge_coef)\n",
    "    if loss_ridge < best_ridge_loss:\n",
    "        best_ridge_loss = loss_ridge\n",
    "        best_ridge_coef = ridge_coef\n",
    "        best_ridge_weights = w_ridge\n",
    "    print(f\"Ridge Regression (alpha={ridge_coef}): Loss = {loss_ridge}\")\n",
    "\n",
    "best_log_gamma = 0\n",
    "best_log_loss = np.inf\n",
    "best_log_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_logistic, loss_logistic = implemented_functions.logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "    if loss_logistic < best_log_loss:\n",
    "        best_log_loss = loss_logistic\n",
    "        best_log_gamma = gamma\n",
    "        best_log_weights = w_logistic\n",
    "    print(f\"Logistic Regression: Loss = {loss_logistic}\")\n",
    "\n",
    "best_log_reg_coef = 0\n",
    "best_log_reg_loss = np.inf\n",
    "best_log_reg_weights = None\n",
    "for gamma in [0.01, 0.1]:\n",
    "    for reg_coef in [0.001, 0.01, 0.1]:\n",
    "        w_reg_logistic, loss_reg_logistic = implemented_functions.reg_logistic_regression(y_train, x_train, reg_coef, initial_w, max_iters, gamma)\n",
    "        if loss_reg_logistic < best_log_reg_loss:\n",
    "            best_log_reg_loss = loss_reg_logistic\n",
    "            best_log_reg_coef = reg_coef\n",
    "            best_log_reg_weights = w_reg_logistic\n",
    "        print(f\"Regularized Logistic Regression (alpha={reg_coef}, gamma={gamma}): Loss = {loss_reg_logistic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e5dd05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD is 8.870000000000001%\n",
      "F1 score SGD is 0.16294663359970607\n",
      "Accuracy of Least Squares is 91.3925%\n",
      "F1 score Least Squares is 0.10315186246418338\n",
      "Accuracy of Ridge is 75.62%\n",
      "F1 score Ridge is 0.3702699212191657\n",
      "Accuracy of Logistic is 0.0%\n",
      "F1 score Logistic is nan\n",
      "Accuracy of Regularized Logistic is 0.0%\n",
      "F1 score Regularized Logistic is nan\n",
      "Accuracy of Regularized Lasso is 0.0%\n",
      "F1 score Regularized Lasso is nan\n",
      "Accuracy of SGD is 8.870000000000001%\n",
      "F1 score SGD is 0.16294663359970607\n",
      "Accuracy of Least Squares is 90.2775%\n",
      "F1 score Least Squares is 0.36214531736919797\n",
      "Accuracy of Ridge is 56.005%\n",
      "F1 score Ridge is 0.2779419005416051\n",
      "Accuracy of Logistic is 0.0%\n",
      "F1 score Logistic is nan\n",
      "Accuracy of Regularized Logistic is 0.0%\n",
      "F1 score Regularized Logistic is nan\n",
      "Accuracy of Regularized Lasso is 0.0%\n",
      "F1 score Regularized Lasso is nan\n",
      "Accuracy of SGD is 8.870000000000001%\n",
      "F1 score SGD is 0.16294663359970607\n",
      "Accuracy of Least Squares is 91.14%\n",
      "F1 score Least Squares is 0.0028137310073157004\n",
      "Accuracy of Ridge is 87.7375%\n",
      "F1 score Ridge is 0.4136282127913927\n",
      "Accuracy of Logistic is 0.0%\n",
      "F1 score Logistic is nan\n",
      "Accuracy of Regularized Logistic is 0.0%\n",
      "F1 score Regularized Logistic is nan\n",
      "Accuracy of Regularized Lasso is 0.0%\n",
      "F1 score Regularized Lasso is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.7 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.71 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.72 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.73 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.75 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.76 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.77 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.8 is nan\n",
      "Accuracy of Logistic is 0.0%\n",
      "-----Logistic: F1 score Logistic at threshold 0.9 is nan\n",
      "Accuracy of Ridge is 87.7375%\n",
      "-----Ridge: F1 score Ridge at threshold 0.7 is 0.4136282127913927\n",
      "Accuracy of Ridge is 88.14%\n",
      "-----Ridge: F1 score Ridge at threshold 0.71 is 0.41316180108857004\n",
      "Accuracy of Ridge is 88.515%\n",
      "-----Ridge: F1 score Ridge at threshold 0.72 is 0.41298236647073855\n",
      "Accuracy of Ridge is 88.815%\n",
      "-----Ridge: F1 score Ridge at threshold 0.73 is 0.40882663847780126\n",
      "Accuracy of Ridge is 89.4425%\n",
      "-----Ridge: F1 score Ridge at threshold 0.75 is 0.40310954063604243\n",
      "Accuracy of Ridge is 89.6725%\n",
      "-----Ridge: F1 score Ridge at threshold 0.76 is 0.39895242252291574\n",
      "Accuracy of Ridge is 89.905%\n",
      "-----Ridge: F1 score Ridge at threshold 0.77 is 0.39351156503454493\n",
      "Accuracy of Ridge is 90.4025%\n",
      "-----Ridge: F1 score Ridge at threshold 0.8 is 0.3670239076669415\n",
      "Accuracy of Ridge is 91.32000000000001%\n",
      "-----Ridge: F1 score Ridge at threshold 0.9 is 0.25970149253731345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import implemented_functions\n",
    "\n",
    "\n",
    "def test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.5):\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, w_sgd, \"SGD\", threshold)\n",
    "    print(f\"F1 score SGD is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, w_least_squares, \"Least Squares\", threshold)\n",
    "    print(f\"F1 score Least Squares is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_ridge_weights, \"Ridge\", threshold)\n",
    "    print(f\"F1 score Ridge is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_weights, \"Logistic\", threshold)\n",
    "    print(f\"F1 score Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_reg_weights, \"Regularized Logistic\", threshold)\n",
    "    print(f\"F1 score Regularized Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_lasso_weights, \"Regularized Lasso\", threshold)\n",
    "    print(f\"F1 score Regularized Lasso is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    return y_pred\n",
    "\n",
    "def test_thresholds(x_test, y_test, weights, method):\n",
    "    for threshold in [0.7, 0.71, 0.72, 0.73, 0.75,0.76, 0.77, 0.8, 0.9]:\n",
    "        accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, weights, method, threshold)\n",
    "        print(f\"-----{method}: F1 score {method} at threshold {threshold} is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.5)\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.3)\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.7)\n",
    "\n",
    "test_thresholds(x_test, y_test, best_log_weights, \"Logistic\")\n",
    "test_thresholds(x_test, y_test, best_ridge_weights, \"Ridge\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "89041a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., ..., -1.,  1., -1.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_ridge_weights, \"Ridge\", threshold=0.72, mode='submission')\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "41833652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [i for i in range(328135, 437513+1)]\n",
    "import helpers\n",
    "helpers.create_csv_submission(ids, y_pred, 'submission3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbba3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8658, 575)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af01490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 561)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74e913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empiricalmethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
