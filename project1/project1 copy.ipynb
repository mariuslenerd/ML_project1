{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e6083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cross_validation' from '/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/cross_validation.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import data_preprocessing\n",
    "import importlib\n",
    "importlib.reload(data_preprocessing)\n",
    "import cross_validation\n",
    "import TEST\n",
    "importlib.reload(TEST)\n",
    "importlib.reload(cross_validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e42811",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "x_train_raw, x_test_raw,y_train_raw, train_ids, test_ids = load_csv_data('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9001d786",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(x_train_raw.shape)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(x_test_raw.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'x_train_raw' is not defined"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(x_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88380452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat y_train to have 0's instead of -1's\n",
    "y_train_original = y_train_raw.copy()\n",
    "y_train_raw[y_train_raw == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f793521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace NaN by a float to treat NaN as a categorical feature\n",
    "x_test_raw = np.nan_to_num(x_test_raw, nan = -10.0)\n",
    "x_test_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75961310",
   "metadata": {},
   "source": [
    "### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1db0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annoted = data_preprocessing.read_annotated_csv('dataset/data_anotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc22ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/data_preprocessing.py:134: RuntimeWarning: invalid value encountered in divide\n",
      "  data = data / data.max(axis=0)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test = data_preprocessing.preprocess_data2(x_train_raw[:200000,:], y_train_raw[:200000], x_test_raw[:200000,:], data_annoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8852ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34992, 575)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f61bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34992, 575)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbaed223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\\nx_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\n",
    "x_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf84a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\\ndata_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\n",
    "data_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14361aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('x_train_preprocessed.csv', x_train, delimiter=',')\n",
    "np.savetxt('y_train_preprocessed.csv', y_train, delimiter=',')\n",
    "np.savetxt('x_test_preprocessed.csv', x_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec040d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8878de0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34992, 575)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:140: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(tx,y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: Loss = 0.07607700864822234\n",
      "Mean Squared Error SGD (gamma=0.01): Loss = [0.24963333333333335, 0.24963333333333335, 0.1324468764749816, 0.11051735832286061, 0.10658942031100394, 0.114244303944985, 0.10953664216244857, 0.14479800756862926, 0.10978548630137756, 0.1199282526110518, 0.10534761002553344, 0.12106909516689825, 0.10320909910953723, 0.12955341913492852, 0.13123231903673926, 0.2063134368043491, 0.12348434203076745, 0.11910055565678743, 0.09945971252867224, 0.10077822041449612, 0.12602589960141838, 0.10044073015208803, 0.11492331360564595, 0.09926595013806609, 0.13135794865615652, 0.09632281737568231, 0.09792005283179483, 0.13799774854196104, 0.10298721961541804, 0.10373320087915927, 0.11628509429650566, 0.10958809793189439, 0.10630191865013261, 0.1662987571365614, 0.09811035530100795, 0.10931058600306331, 0.09911277735763416, 0.09876225423389681, 0.10254382520857533, 0.11174921652115868, 0.11185971612020965, 0.10031086422256763, 0.11811767646713588, 0.10017351455325225, 0.12457962754083604, 0.12277943962491443, 0.2059075999064636, 0.21651552678585304, 0.10415582852906857, 0.10022869667252442, 0.09916274144846197, 0.14906165316462305, 0.2145105073463379, 0.18636842098430328, 0.16030195354237273, 0.1061880527656075, 0.10139320511315539, 0.13410529864861293, 0.1090856256724589, 0.10962544027665257, 0.1093208097532239, 0.1352384285658232, 0.10812646470501301, 0.12029234511053152, 0.11318472227931725, 0.21188694562526386, 0.19194300913002926, 0.1645767810944734, 0.11326539999509096, 0.11525674908366194, 0.12195278944447097, 0.16785833398568364, 0.1122416782173262, 0.11376207325329385, 0.118093164256724, 0.11019107655826835, 0.1261568554211247, 0.1872139529971302, 0.1256030534094441, 0.12580344763252876, 0.1209054410641871, 0.12017589779537066, 0.12042163179961173, 0.13806163948022607, 0.15061986339499747, 0.11889612229418503, 0.12766359864188664, 0.17176098139633167, 0.11624706285819704, 0.12591400912060244, 0.2013406283152978, 0.21794771652986575, 0.1513953492265215, 0.10550057565958748, 0.11771301495742591, 0.11294138781350825, 0.10397303520666211, 0.11993072671750667, 0.11488095082807505, 0.11141737791695278, 0.10686691088499499, 0.16207760574806168, 0.10297456677158162, 0.10238257922031015, 0.11281284508989099, 0.22405477296591494, 0.19978494343583195, 0.11810025815403206, 0.13953977581932633, 0.11042245817215295, 0.18757859640039737, 0.15196895565807028, 0.097730759230908, 0.11293129855945482, 0.10234115810634119, 0.10892291174922734, 0.10847474941465914, 0.11898804647750102, 0.12074753604214081, 0.09372920006646626, 0.0915693228978231, 0.096705802926767, 0.10447351953996713, 0.11256601923292696, 0.10226623094728347, 0.09163755393606798, 0.09629924499963331, 0.13316801199049474, 0.11835078871403266, 0.09624385434186619, 0.09351620105462344, 0.10592928718570949, 0.1058377317344172, 0.13609707084394296, 0.20439511187863435, 0.10321444688230322, 0.0991135003407441, 0.09347157888514804, 0.12227544963992305, 0.10588304974194432, 0.09860808923218714, 0.11224781943507664, 0.0942962808887013, 0.09420713504522447, 0.09466130755571628, 0.09850373706207534, 0.09455265883132591, 0.10187085952111043, 0.10612726660898769, 0.09531405724178545, 0.1008062514685246, 0.0969888969089711, 0.17293351682637254, 0.0965388681126347, 0.09719090313613551, 0.0959125987318233, 0.09786242216567773, 0.17464856069522702, 0.12089718326491238, 0.11065523499887847, 0.10550731102999199, 0.09489998340918984, 0.1328359712089699, 0.10608141982528796, 0.09468140276140508, 0.09420109611321843, 0.10170377842922355, 0.10514775957545414, 0.17577366082910026, 0.11539794766330885, 0.1614720610086396, 0.1798100069598156, 0.11944312180245469, 0.10223682944181986, 0.11051543561408696, 0.12821834058925388, 0.10157152633102114, 0.10207825814348656, 0.10907972229672673, 0.10197842024012055, 0.10143395338997134, 0.10842358041224007, 0.10443946409946424, 0.11110356737520063, 0.13639826061186022, 0.13973556513991411, 0.11893470932124323, 0.15604974598810775, 0.09498371101151248, 0.10215332306921157, 0.12332607488386806, 0.13319485574263135, 0.1326011251805441, 0.14878160088516307, 0.12927167019072744, 0.13333077954958936, 0.09728521482042479, 0.11362004864432003, 0.12673080969480954, 0.0935061940631287, 0.10822821843724739, 0.1040531339050633, 0.10531506897466578, 0.0957243001118268, 0.10387516573715548, 0.09519951120007297, 0.09585373733908885, 0.09575150688474376, 0.10098972544098471, 0.09643526842112701, 0.09855427279602458, 0.09946832477831938, 0.09971655151904685, 0.10261934072102026, 0.11811147220155396, 0.10375798078694223, 0.11153731440868885, 0.09731456434579396, 0.09628861912635774, 0.09636686841899904, 0.09744528831708725, 0.11064940731931233, 0.12208893655139863, 0.1063304141853234, 0.100613803547566, 0.16289327680386753, 0.09651464402006121, 0.10378979389954462, 0.09958527016061737, 0.15482709864595023, 0.25328200865910855, 0.17047799434248972, 0.10204192184091591, 0.15386172709083, 0.10568797477797327, 0.10899689327953076, 0.1161197743174788, 0.1001224216947581, 0.1217155373953992, 0.1073384098499249, 0.09568958465463134, 0.09735973518844139, 0.09599444115535677, 0.09924517207368717, 0.09640691894044803, 0.09593793158364888, 0.14974663170231386, 0.11056706594371965, 0.22814304744244882, 0.19128458033182413, 0.12211052642963804, 0.15048412159483712, 0.10841404172349131, 0.09963992741811016, 0.11720458467596515, 0.14511641015482607, 0.14361702032107568, 0.10027647185101583, 0.15344256039308593, 0.1180613154322233, 0.09663436332532482, 0.09828066800854729, 0.09828652470557712, 0.096991493532939, 0.09552345945413933, 0.0997426480986154, 0.1017699980668134, 0.12911514559547904, 0.10035741650750403, 0.09346141236354637, 0.115893757943691, 0.10319499210678287, 0.09600928683317092, 0.10591021893274087, 0.1139262294815867, 0.09354620814550496, 0.10376469716759058, 0.09630108144780132, 0.09779522097359396, 0.09428469949846048, 0.11107472203863411, 0.16583570623987653, 0.10717953395776961, 0.18742090807458045, 0.10172535553908908, 0.09414347018191305, 0.09402721059359859, 0.09668192905379525, 0.14376365414603087, 0.11353553145177281, 0.09592698205967395, 0.18161416620172757, 0.15443570291235587, 0.17925880592839463, 0.09904291292614827, 0.13450109292153045, 0.11457400358526817, 0.10769610374572579, 0.10510620913183631, 0.11853382743016216, 0.10788292688505514, 0.09534865762754893, 0.1413847638467353, 0.11860378588768594, 0.11452429046360513, 0.10818614427502915, 0.0918373937892489, 0.1672992357334602, 0.13033857216999808, 0.09379297211762727, 0.0946543195886158, 0.10954203941076425, 0.1288685172524503, 0.1325711106661366, 0.1654260509602983, 0.10910975248398508, 0.10374366099682357, 0.09792087670081896, 0.09954206953754183, 0.11078835769666512, 0.17722471825641656, 0.11890480742088377, 0.11933258644285126, 0.13967349466352091, 0.09582742272274847, 0.10942652407105531, 0.09674195191792992, 0.11318354663306665, 0.10777076907494884, 0.09797031309331257, 0.09848557159227045, 0.09691139852490038, 0.10363027986507072, 0.10999639275583006, 0.21193586679040402, 0.12462054118873621, 0.1028789825721113, 0.10067719298777213, 0.10229385813621693, 0.11989072965264662, 0.10826937538617781, 0.09982736679464045, 0.10489091168786507, 0.09811530137098116, 0.11183933471179686, 0.14367270683904912, 0.11313159819679747, 0.11081733706153771, 0.1033863366763196, 0.11709674918217643, 0.1078515144658312, 0.09834448036573273, 0.10153252024923738, 0.1833232241313083, 0.13888244900136576, 0.1284268174228129, 0.09959228624130478, 0.11003515236650332, 0.09705981586816619, 0.1114638707205946, 0.09968926684885303, 0.09744766344469469, 0.12911543583382615, 0.0953485808396004, 0.1415582689971035, 0.10282555804744703, 0.11901486923533837, 0.09751416328669729, 0.17931688290539227, 0.3773088609514683, 0.34800621216215, 0.23811403414145885, 0.273499697385083, 0.14838719038225023, 0.10141926335174443, 0.10884626487145965, 0.1056186832318923, 0.20070013181307605, 0.1879579998247566, 0.21674343639068783, 0.10247215128319619, 0.11803422204921152, 0.11606380433019578, 0.13865638181021725, 0.10111783852382965, 0.10035431000531138, 0.15827763588712596, 0.09695080215831539, 0.10507598554051968, 0.09587938180060342, 0.13337556911169407, 0.09378194185174221, 0.09310213640812254, 0.10498928967726866, 0.0933035642861768, 0.09309614249474298, 0.09451749870914568, 0.09599993082469421, 0.11417138829077399, 0.22222897220265103, 0.1266254909700654, 0.1291659783402489, 0.09333299361505441, 0.1217233968800494, 0.12846220735800146, 0.12186807206223361, 0.12065806649612408, 0.09669786250568062, 0.10072975937902479, 0.1049171251381452, 0.10419796858275203, 0.09393831764273604, 0.10050193829831688, 0.09515398352251227, 0.10117480687396883, 0.09834640138864542, 0.11247065034669686, 0.15682726967270144, 0.10848879544391549, 0.1375629507473516, 0.1915453571039982, 0.2640412405335817, 0.2865974414349521, 0.177940419452113, 0.0970770978984812, 0.10859749848006531, 0.09559523654513911, 0.09486441605711295, 0.10185951408802682, 0.10027836146322859, 0.10804623814608434, 0.0964955170509797, 0.09633309687646834, 0.09823535936185962, 0.12166676170479654, 0.09902907264821398, 0.11409863920729203, 0.09831240319683542, 0.11339867097125435, 0.15208409814141177, 0.16051261060778577, 0.15364753579663606, 0.14429689987633812, 0.10488029254341619, 0.14333138883202873, 0.19875110949094862, 0.1033943400829505, 0.10594160620704986, 0.10989118235112638, 0.11176434207195625, 0.12991058406447323, 0.12154688980408387, 0.10449279750278326, 0.11162857756275538, 0.10359326090017162, 0.10240801855204225, 0.10689682983174636, 0.14617500497548785, 0.10904935044898752, 0.10777164761925209, 0.10659932604667606, 0.10655391824813723, 0.1089442213646179, 0.10343485698673272, 0.11692838111701086, 0.1419247063762402, 0.21671823047449792, 0.14032794282538855, 0.1362773090161268, 0.10538590842763611, 0.1837613563088525, 0.12101031647656174, 0.11736578557892717, 0.12527339898731518, 0.1040478939073209, 0.1136422571966402, 0.11674762133764781, 0.13411485024543274, 0.1054286586786266, 0.10468987893327227, 0.10759611598445742, 0.10857136394347684, 0.10484187237841448, 0.1360380705848867, 0.10813519353251767, 0.12302073568462632, 0.10587177994600071, 0.11093837256729124, 0.10515132271707699, 0.10477933780721718, 0.10894866514051481, 0.14372463163032145, 0.16594087637017252, 0.18457044405964068, 0.15955391733310098, 0.1436796160379999, 0.12949614845867302, 0.09892615890340581, 0.12897344160553104, 0.10543931673942038]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:53: RuntimeWarning: overflow encountered in matmul\n",
      "  MSE_loss = 1 / (2*N) * (e.T @ e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error SGD (gamma=0.1): Loss = [0.24963333333333335, 7.437231955443623, 122.34866885221157, 1716.7928340101423, 32494.68518103243, 291079.71073823643, 3356872.801955557, 17721452.76414747, 57338719.76843583, 931824649.0579454, 501563525.1012139, 910731715.1101241, 31882657966.359913, 459359332969.815, 5955161695727.301, 33659564332294.3, 607464576894295.4, 6545646622327961.0, 5913489909300679.0, 1.4375959732394098e+17, 1.1032881332544009e+18, 4.853577915433296e+18, 2.3348919132428774e+18, 2.8625469324615397e+19, 8.464853086591842e+20, 6.132458850472798e+21, 6.7398295015879994e+22, 1.2692156487102919e+24, 1.5003181036828727e+25, 4.1272989933093275e+26, 3.2366831061132595e+27, 2.303715322723041e+28, 1.903954300148722e+28, 3.060433033240543e+29, 2.977497562413907e+30, 2.260123159683616e+31, 4.344122773565791e+32, 1.7301063330184492e+33, 1.1009717637800933e+34, 1.2152448858318604e+35, 2.931839170701566e+35, 2.5227412228970053e+36, 4.945481217791109e+37, 5.517912705283061e+38, 1.9867316740631025e+39, 3.479487235745081e+39, 4.867317663505933e+40, 2.6199757585718953e+41, 9.56610757713907e+41, 8.753036714182668e+42, 5.157848231683673e+43, 1.0186630870402404e+45, 1.6833364845895665e+46, 1.6998878012861907e+46, 7.761823339372178e+46, 2.299860842546903e+48, 3.397740173323091e+49, 3.036482399756287e+50, 2.114893941782926e+51, 1.8887671393182957e+52, 1.3894607817417266e+52, 2.5309812294524293e+53, 4.5167321656666436e+54, 6.00709503896099e+55, 6.415410063493489e+56, 5.507995865041892e+57, 9.229122921018124e+58, 6.470315309199931e+59, 1.1463271350824296e+61, 9.457070272554695e+61, 7.1873113379388355e+62, 3.55148614743406e+63, 1.0369955069326184e+65, 7.284347822160692e+65, 2.434473136823541e+66, 1.3186295436000815e+67, 8.104948006514081e+67, 1.383444685096947e+69, 1.58045305052684e+70, 2.128007788837175e+71, 1.535157193781944e+72, 9.640214215881562e+72, 4.3029772845229304e+73, 5.501711731059461e+74, 3.1781502919441278e+75, 1.2839779654773467e+76, 9.283805421201699e+76, 1.790568130514547e+77, 3.714283624668886e+77, 8.932343613209528e+78, 2.2993063870197205e+80, 2.4054921166612525e+81, 2.8152021759462223e+82, 1.4701029744054311e+83, 2.156633956770738e+84, 2.4001053123264904e+84, 3.533770989047284e+85, 1.1930535511291698e+86, 8.704214399128952e+86, 8.047237956071327e+86, 6.3796584271185085e+87, 6.960560679284377e+88, 1.0491725332047338e+90, 1.151961570483001e+91, 5.1209126531600456e+91, 2.4217598165144315e+92, 6.55567066559981e+93, 7.160233828744825e+94, 1.3512879943037512e+96, 5.902000438146729e+96, 7.260875080796286e+97, 9.686353595424381e+98, 1.1812180852901018e+100, 4.855835059485088e+100, 1.6294177273785812e+101, 2.4531749793660147e+102, 2.6002245909755466e+103, 2.2704513040211297e+104, 1.8131256635578017e+105, 1.3793180454608123e+106, 1.5827403033221208e+107, 1.1957153670714428e+108, 1.2514157076904224e+109, 7.557412859237455e+109, 4.3577217404607484e+110, 4.02524428053542e+111, 1.1760762681829324e+112, 5.3117309104848055e+112, 1.0337724306620581e+113, 6.561976579001989e+113, 7.609134579748585e+114, 1.5663152648908397e+116, 2.1938778650079612e+117, 1.5984765033694913e+118, 9.919561131344265e+117, 9.386852633236192e+118, 5.883783696798103e+119, 2.8224262744218224e+119, 1.2663246555936643e+121, 8.988413027624686e+121, 7.851175146531195e+122, 6.690599314520152e+123, 9.847345737088557e+124, 2.606150370670802e+125, 4.9621533382118636e+126, 9.378524970652306e+127, 1.189360159685296e+129, 2.1286846371292575e+130, 2.447266467770883e+131, 2.2265599800473284e+132, 2.667159163488014e+133, 4.79920558763978e+134, 6.246817805101799e+135, 1.4432661158741174e+137, 4.1598708279958775e+137, 1.3146721427573301e+138, 3.6024312641046444e+138, 3.216271049896999e+138, 5.653895917442612e+139, 6.555484045542191e+140, 6.784798187430392e+141, 1.8726601113394611e+142, 5.616141849282113e+142, 6.070206533620224e+143, 3.9141405615317474e+144, 5.678230657905619e+145, 1.0619539548270512e+147, 8.413327466282005e+146, 1.483965438848892e+148, 3.476485709590569e+148, 4.803555117038505e+149, 3.1746592482900857e+150, 1.8896265511800856e+151, 6.581357215871798e+150, 1.797035223169965e+151, 4.252614153183511e+152, 2.4362058618567335e+153, 1.9913708656115518e+154, 3.047942992997134e+155, 2.337634855504002e+156, 3.425034839280671e+157, 2.8259811091300917e+158, 4.515559234199842e+159, 5.1197702845369096e+160, 9.03766551274549e+161, 3.89819700580604e+162, 6.553840606218626e+163, 1.86121632006221e+165, 2.62475638253697e+166, 4.4128224519912894e+167, 6.613712151210247e+168, 7.541408490810608e+169, 5.02553023619681e+170, 8.087123929900788e+171, 8.839304608515246e+172, 2.0110739523231676e+173, 2.122361566584779e+174, 3.930049854717608e+175, 4.7310415937899625e+176, 4.0335038929645847e+177, 5.3327885174726465e+178, 7.355117615172454e+179, 1.666211560631956e+181, 1.1596662178616849e+182, 2.3018363574567876e+183, 6.096789519975223e+184, 1.0588212910913202e+186, 7.765908699799202e+186, 3.551812841316985e+187, 1.3502367315033453e+187, 8.268646965660333e+186, 4.3388305484407776e+188, 3.6282345514302453e+189, 2.6750328466361112e+190, 4.672164023924533e+190, 1.1447189858158123e+191, 1.4228565116281253e+191, 5.926894048834319e+191, 2.8446009295624986e+192, 2.1716119154337424e+192, 1.5055605759592678e+192, 9.841143724622556e+193, 8.492324307379572e+194, 1.3542735828468457e+196, 1.0040305064459428e+197, 8.02466157011456e+197, 9.026660508579352e+198, 5.602703866497578e+199, 5.247867009191363e+200, 9.417008426139799e+201, 6.271863176148474e+202, 6.069921964382856e+203, 5.323312389461612e+204, 3.0546842163016807e+205, 4.382777652018759e+206, 3.3449313745155224e+207, 1.8803541865387884e+208, 2.5241908526573434e+209, 3.9676307380635445e+210, 6.693461869733488e+211, 4.0185141543539996e+212, 2.4393417244378457e+213, 6.006067297522676e+213, 1.144640173826349e+215, 2.1063913052166855e+215, 7.425238717840353e+215, 1.9451954596477524e+216, 7.451995808113747e+216, 9.639964523455496e+217, 1.0537940193929055e+219, 7.727542857537381e+219, 1.3719319048491106e+221, 2.5223285539851366e+222, 1.5213096403008675e+223, 3.202824735910929e+223, 2.553444643798469e+223, 1.8919305559689417e+224, 1.9677216841729003e+225, 2.1772983437910952e+226, 3.4309430660895476e+227, 3.986905969437629e+228, 1.6608862395745357e+229, 2.245190206029983e+229, 4.2393561405581795e+229, 2.0363105119519045e+229, 3.132123286846488e+230, 7.820700235331628e+230, 1.760927626711424e+232, 1.6549525860383182e+233, 1.680822326265004e+234, 3.774228249512231e+234, 3.405300163745061e+235, 6.53328676006923e+236, 6.387360054262512e+237, 4.807309569450924e+238, 5.641246513624629e+239, 9.105435507506975e+240, 1.0592377165644522e+242, 8.423271800675703e+242, 7.164953107494951e+242, 3.093656929086091e+244, 2.4930979206727987e+245, 1.9388743985192591e+245, 3.3267573633851225e+246, 5.009016543638123e+247, 5.295305802588984e+248, 2.1385111908280324e+249, 1.425153395566297e+250, 7.224270883468026e+250, 3.648781198059946e+251, 4.5593188388158756e+251, 7.09324657186798e+251, 3.6183847655295417e+252, 5.265475366059285e+253, 6.632907432325887e+254, 1.0746183089589048e+256, 1.6201011032646493e+257, 1.7705223081031845e+258, 1.3996004719295573e+259, 9.621686224054719e+259, 1.8295149586116574e+261, 1.1853085851842095e+262, 2.1165478275851274e+262, 3.294341515734909e+262, 5.11940350617094e+263, 3.73747788036255e+264, 2.9739549732158287e+265, 5.278476798722791e+266, 2.6245652358987336e+267, 3.1139946827938665e+268, 1.8314975074202868e+269, 2.8131536421098264e+270, 1.5353096689648002e+271, 2.3194161136097957e+272, 1.1962846909436077e+273, 9.996053204381106e+273, 1.5056923904024994e+274, 2.850749712186318e+275, 5.659994308247564e+276, 1.7488245387964723e+277, 1.2736490352399999e+277, 1.2380082589107821e+278, 8.726644459571153e+278, 2.712816220218798e+279, 2.4613214100699667e+280, 5.352861999564784e+281, 2.971358869152982e+282, 8.511418542593866e+282, 8.703163615499404e+283, 1.1420949302668107e+285, 5.794252413642694e+285, 5.605676865906972e+286, 8.174142393488268e+287, 1.1032973601342802e+289, 1.025312489539194e+290, 4.790658556984028e+290, 5.970664343528365e+291, 6.745315391129512e+292, 1.368642592935978e+294, 1.923210320496783e+295, 1.854154274626232e+296, 2.2068382042317457e+297, 1.0171103690977969e+298, 6.166445305018104e+297, 3.838974167866522e+298, 4.1755617582927306e+299, 9.488974320485436e+300, 2.9653743552245633e+301, 1.1855794549926818e+302, 6.110149509364283e+302, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:52: RuntimeWarning: overflow encountered in matmul\n",
      "  e = y - tx @ w\n",
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:74: RuntimeWarning: overflow encountered in matmul\n",
      "  e = y- tx@w\n",
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:75: RuntimeWarning: invalid value encountered in matmul\n",
      "  return -(tx.T@e)/n\n",
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:52: RuntimeWarning: invalid value encountered in matmul\n",
      "  e = y - tx @ w\n",
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:74: RuntimeWarning: invalid value encountered in matmul\n",
      "  e = y- tx@w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error SGD (gamma=0.5): Loss = [133.45745724713146, 37269.45169957798, 6079265.489907652, 2464273447.6025925, 1050726250984.4596, 257129729778912.8, 8.483591859579653e+16, 2.9766977720724615e+19, 1.5347900282193043e+22, 6.142193426222809e+24, 5.6881516798247336e+26, 3.738709940514133e+29, 1.9621559217042897e+32, 1.3560721923196953e+35, 5.905410416201369e+37, 2.056958840486567e+40, 9.238321194421974e+42, 2.381388158358418e+45, 4.765869527830146e+47, 3.0860512840363073e+50, 1.0518641668102186e+53, 6.280770542253679e+55, 2.505537458557544e+58, 9.069055705676407e+60, 2.110459098323442e+63, 6.624180497519972e+65, 2.3393998682077074e+68, 1.3866411322403428e+71, 2.4335482638326638e+73, 5.706897026506024e+75, 2.866094476015283e+78, 1.8826086559565211e+81, 1.1345003219594138e+84, 3.2978200625107694e+86, 1.0346315017589494e+89, 3.8106166287645426e+91, 1.3846316551149161e+94, 3.38458008969471e+96, 1.2504711275004765e+99, 3.3901630645023055e+101, 1.1516628981247766e+104, 5.985036179224966e+106, 2.5846448491089436e+109, 2.56352822636982e+111, 4.539775360028583e+113, 5.402332904611197e+115, 1.9845060462801411e+118, 8.209492883868232e+120, 4.032704505323702e+122, 1.0560885351236794e+125, 3.571489521770752e+127, 2.393415238878224e+130, 8.711054963521174e+132, 4.2861300982590955e+135, 3.899224511416016e+137, 1.2820252432970316e+140, 4.041386173124174e+142, 2.808634472078943e+145, 7.569544243319236e+147, 1.088314358469767e+150, 6.648891841861579e+152, 2.6009963085681376e+155, 1.0244591333633146e+158, 2.993286444958914e+160, 1.4348990015949163e+163, 9.224210036634417e+165, 1.8877463204333735e+168, 1.3553591439397734e+171, 5.844163675442373e+173, 6.778482132922086e+175, 3.326265579430693e+178, 1.3285089843810505e+181, 4.951962148933033e+183, 1.2688411691961104e+186, 1.0606839598900133e+189, 5.0357409271968824e+191, 2.1637752760389704e+194, 1.6132139849408234e+197, 2.8113677461063634e+199, 1.6108708600437254e+202, 7.187493273057521e+204, 3.626367720842688e+207, 9.703337405231014e+209, 4.689701819404931e+212, 3.7993519710026137e+214, 2.482000124189495e+217, 4.870090607104421e+219, 7.359490188939263e+221, 3.4494185282329424e+224, 1.1195088949952116e+227, 6.349315146140436e+229, 2.1699265650170862e+232, 9.776972718298738e+234, 3.968065684081098e+237, 3.200190560103044e+239, 2.658382969456456e+242, 5.3220059476242935e+244, 2.2298043778152436e+247, 6.027158883877516e+249, 3.671695498835725e+252, 1.9518152652103527e+255, 1.2618974056504444e+258, 3.6557204983218804e+260, 1.1987338385894777e+263, 2.971113322240767e+265, 9.606530771423555e+267, 2.2015268414620565e+270, 2.6757979396124698e+272, 1.3478341710750093e+275, 8.27159589975742e+277, 8.511267543953636e+279, 4.422931262398332e+282, 1.0831627852842358e+285, 7.023664105366726e+287, 2.8521971520695956e+290, 7.368185246303883e+292, 4.65584592136941e+295, 1.5707140202356542e+298, 7.406812879104111e+300, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Mean Squared Error SGD (gamma=1): Loss = [1004.2831519468123, 1622989.7145280407, 1092431969.7731516, 1663828821978.5571, 1620380166373419.0, 1.634606483454896e+18, 5.671278647439416e+21, 7.766485751290179e+24, 1.4364025944976452e+28, 3.2048030223906043e+31, 4.1172704937122607e+34, 4.473313059142288e+37, 7.997563390259272e+40, 3.6895151182496193e+43, 6.887778181302738e+46, 6.881819125385835e+49, 4.663727810421781e+52, 6.839785230327068e+55, 7.138418719903557e+58, 1.0724741555227328e+62, 1.8636055286026377e+65, 3.3835217920598326e+68, 3.4371579424666485e+71, 6.148235474776046e+74, 1.604512037628137e+78, 4.152951861763237e+81, 2.606501678026818e+84, 2.1120896846673543e+87, 4.68068193499682e+90, 1.9119865802703978e+93, 3.195793220319884e+96, 8.550057342144251e+99, 2.7131867361749552e+103, 3.0098285956232463e+106, 6.642642461912583e+109, 9.905119564108392e+112, 1.0936775360741398e+116, 2.841711885903191e+119, 7.587017834744315e+122, 1.7785792655627888e+126, 3.59692540804705e+129, 5.290212038526099e+132, 9.34511730000746e+135, 1.5527259901364636e+139, 1.2167872878381456e+142, 2.2900824912900714e+145, 1.7720029860953773e+148, 1.3222686114215966e+151, 4.599780405897092e+154, 1.0428487803507169e+158, 3.0941078075322563e+161, 3.7647467229487233e+164, 8.600935843782163e+167, 2.2132855738844684e+171, 3.799809838515249e+174, 2.721979231646474e+177, 7.111140011843197e+179, 1.1668526314899414e+183, 1.69336752603549e+186, 1.6593146045115006e+189, 3.0868227000475495e+192, 3.7853940290375135e+195, 4.2224154412852574e+198, 1.2342180898406881e+202, 1.8285442111520067e+205, 1.366539675467437e+208, 5.824681854700333e+210, 4.6725385789349476e+213, 3.726925265433068e+216, 4.892434848699264e+219, 1.6734117553297213e+223, 3.4274962051502446e+226, 7.25954266167755e+229, 8.732599428068484e+232, 1.6532453374666624e+236, 1.7526349058429079e+239, 2.1326783803890186e+242, 4.763673914008808e+245, 1.1971970247765692e+249, 2.7297142524156436e+252, 1.1306614309604757e+255, 1.0021565917051013e+258, 1.692834888307429e+261, 2.1926217129379794e+264, 7.188660678541247e+267, 1.3758713732058675e+271, 6.535719214955425e+273, 4.498136701731156e+276, 2.880927107230093e+279, 5.770198351980116e+282, 3.8817039509525047e+285, 2.5432568905705e+288, 6.529080615044542e+291, 1.2490973173140296e+295, 1.4127765864935186e+298, 1.9275402646869273e+301, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.1): Loss = 0.7198276169804539\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.01): Loss = 0.5693886181718885\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.1): Loss = 0.9926453655268873\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.01): Loss = 0.5588344280436274\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.1): Loss = 4.729232815660527\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.01): Loss = 1.1992341846159786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  A = tx.T @ tx + (N * lambda_) * np.eye(D)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression (alpha=0.001): Loss = 0.07695916340197566\n",
      "Ridge Regression (alpha=0.01): Loss = 0.0784725188049163\n",
      "Ridge Regression (alpha=0.1): Loss = 0.0826877177626074\n",
      "Ridge Regression (alpha=1): Loss = 0.09835680128765587\n",
      "Ridge Regression (alpha=10): Loss = 0.14176705113643404\n",
      "Logistic Regression: Loss = 0.5049874773133046\n",
      "Logistic Regression: Loss = 0.4745818988670817\n",
      "Logistic Regression: Loss = 0.7723572690265244\n",
      "Logistic Regression: Loss = 1.5952092980331682\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.01): Loss = 0.505386607423083\n"
     ]
    }
   ],
   "source": [
    "import implemented_functions\n",
    "import importlib\n",
    "importlib.reload(implemented_functions)\n",
    "\n",
    "initial_w = np.zeros(x_train.shape[1])\n",
    "max_iters = 500\n",
    "gamma = 1\n",
    "\n",
    "x_test = x_train[30000:,:]\n",
    "y_test = y_train[30000:]\n",
    "x_train = x_train[:30000,:]\n",
    "y_train = y_train[:30000]\n",
    "\n",
    "\n",
    "w_least_squares, loss_ls = implemented_functions.least_squares(y_train, x_train)\n",
    "print(f\"Least Squares: Loss = {loss_ls}\")\n",
    "\n",
    "best_mse_coef = 0\n",
    "best_mse_loss = np.inf\n",
    "best_mse_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_sgd, loss_sgd = implemented_functions.mean_squared_error_sgd(y_train,  x_train, initial_w, max_iters, gamma)\n",
    "    if loss_sgd[-1] < best_mse_loss:\n",
    "        best_mse_loss = loss_sgd[-1]\n",
    "        best_mse_coef = gamma\n",
    "        best_mse_weights = w_sgd\n",
    "    print(f\"Mean Squared Error SGD (gamma={gamma}): Loss = {loss_sgd}\")\n",
    "\n",
    "best_log_lasso_coef = 0\n",
    "best_log_lasso_loss = np.inf\n",
    "best_log_lasso_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5]:\n",
    "    for lambda_ in [0.1, 0.01]:\n",
    "        w_log_lasso, loss_log_lasso = implemented_functions.reg_logistic_lasso_subgradient(y_train, x_train, lambda_, initial_w, max_iters, gamma)\n",
    "        if loss_log_lasso < best_log_lasso_loss:\n",
    "            best_log_lasso_loss = loss_log_lasso\n",
    "            best_log_lasso_weights = w_log_lasso\n",
    "        print(f\"Regularized Lasso Logistic Regression (gamma={gamma}, lambda={lambda_}): Loss = {loss_log_lasso}\")\n",
    "        \n",
    "best_ridge_coef = 0\n",
    "best_ridge_loss = np.inf\n",
    "best_ridge_weights = None\n",
    "for ridge_coef in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    w_ridge, loss_ridge = implemented_functions.ridge_regression(y_train, x_train, ridge_coef)\n",
    "    if loss_ridge < best_ridge_loss:\n",
    "        best_ridge_loss = loss_ridge\n",
    "        best_ridge_coef = ridge_coef\n",
    "        best_ridge_weights = w_ridge\n",
    "    print(f\"Ridge Regression (alpha={ridge_coef}): Loss = {loss_ridge}\")\n",
    "\n",
    "best_log_gamma = 0\n",
    "best_log_loss = np.inf\n",
    "best_log_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_logistic, loss_logistic = implemented_functions.logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "    if loss_logistic < best_log_loss:\n",
    "        best_log_loss = loss_logistic\n",
    "        best_log_gamma = gamma\n",
    "        best_log_weights = w_logistic\n",
    "    print(f\"Logistic Regression: Loss = {loss_logistic}\")\n",
    "\n",
    "best_log_reg_coef = 0\n",
    "best_log_reg_loss = np.inf\n",
    "best_log_reg_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5]:\n",
    "    for reg_coef in [0.001, 0.01, 0.1, 1]:\n",
    "        w_reg_logistic, loss_reg_logistic = implemented_functions.reg_logistic_regression(y_train, x_train, reg_coef, initial_w, max_iters, gamma)\n",
    "        if loss_reg_logistic < best_log_reg_loss:\n",
    "            best_log_reg_loss = loss_reg_logistic\n",
    "            best_log_reg_coef = reg_coef\n",
    "            best_log_reg_weights = w_reg_logistic\n",
    "        print(f\"Regularized Logistic Regression (alpha={reg_coef}, gamma={gamma}): Loss = {loss_reg_logistic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5dd05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD is 49.819059107358264%\n",
      "F1 score SGD is 0.0\n",
      "Accuracy of Least Squares is 77.20144752714113%\n",
      "F1 score Least Squares is 0.7744630071599046\n",
      "Accuracy of Ridge is 77.38238841978287%\n",
      "F1 score Ridge is 0.7766527695056581\n",
      "Accuracy of Logistic is 73.16043425814233%\n",
      "F1 score Logistic is 0.6920415224913494\n",
      "Accuracy of Regularized Logistic is 73.10012062726176%\n",
      "F1 score Regularized Logistic is 0.6911357340720221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_accuracy(y_test, x_test, w, method):\n",
    "    y_pred = x_test@w\n",
    "    y_pred[y_pred <= 0.5] = 0\n",
    "    y_pred[y_pred > 0.5] = 1\n",
    "    computed_accuracy = np.sum(y_pred == y_test)/len(y_test)\n",
    "    print(f\"Accuracy of {method} is {computed_accuracy*100}%\")\n",
    "    return computed_accuracy, y_pred\n",
    "\n",
    "def test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights):\n",
    "    accuracy, y_pred = compute_accuracy(y_test, x_test, w_sgd, \"SGD\")\n",
    "    print(f\"F1 score SGD is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = compute_accuracy(y_test, x_test, w_least_squares, \"Least Squares\")\n",
    "    print(f\"F1 score Least Squares is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = compute_accuracy(y_test, x_test, best_ridge_weights, \"Ridge\")\n",
    "    print(f\"F1 score Ridge is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = compute_accuracy(y_test, x_test, best_log_weights, \"Logistic\")\n",
    "    print(f\"F1 score Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = compute_accuracy(y_test, x_test, best_log_reg_weights, \"Regularized Logistic\")\n",
    "    print(f\"F1 score Regularized Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    return y_pred\n",
    "\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c63c635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89041a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m X_max = data_preprocessing.build_poly(x_train, \u001b[32m3\u001b[39m)\n\u001b[32m      2\u001b[39m initial_w = np.zeros(X_max.shape[\u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m cross_validation.cross_validation_demo(y=y_train, x=x_train, k_fold=\u001b[32m5\u001b[39m, lambdas=[\u001b[32m0.001\u001b[39m], degree=\u001b[32m3\u001b[39m, initial_w=initial_w, max_iters=\u001b[32m100\u001b[39m, gamma=\u001b[32m0.1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/cross_validation.py:87\u001b[39m, in \u001b[36mcross_validation_demo\u001b[39m\u001b[34m(y, x, degree, k_fold, lambdas, initial_w, max_iters, gamma, seed)\u001b[39m\n\u001b[32m     84\u001b[39m sums_te = {m: \u001b[32m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m methods}\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_fold):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     res = cross_validation(y, x, k_indices, k, lambda_, degree, initial_w, max_iters, gamma)\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[32m     89\u001b[39m         tr_k, te_k = res[m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/cross_validation.py:46\u001b[39m, in \u001b[36mcross_validation\u001b[39m\u001b[34m(y, x, k_indices, k, lambda_, degree, initial_w, max_iters, gamma)\u001b[39m\n\u001b[32m     44\u001b[39m w_mse_sgd, _loss_mse_sgd = mean_squared_error_sgd(y_tr_k, x_tr_k_poly, initial_w, max_iters, gamma)\n\u001b[32m     45\u001b[39m w_rdg, _loss_rdg         = ridge_regression(y_tr_k,       x_tr_k_poly, lambda_)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m w_ls, _loss_ls           = least_squares(y_tr_k,          x_tr_k_poly)\n\u001b[32m     47\u001b[39m w_lr, _loss_lr           = logistic_regression(y_tr_k,    x_tr_k_poly, initial_w, max_iters, gamma)\n\u001b[32m     48\u001b[39m w_reg_lr, _loss_reg_lr   = reg_logistic_regression(y_tr_k,x_tr_k_poly, lambda_, initial_w, max_iters, gamma)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:140\u001b[39m, in \u001b[36mleast_squares\u001b[39m\u001b[34m(y, tx)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mleast_squares\u001b[39m(y,tx) : \n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    Performs the ordinary least squares regression algorithm and returns the best parameters, along with its associated loss\u001b[39;00m\n\u001b[32m    131\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m \u001b[33;03m        loss : scalar, mean squared error loss\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     w = np.linalg.lstsq(tx,y)[\u001b[32m0\u001b[39m]\n\u001b[32m    141\u001b[39m     loss = compute_loss(y,tx,w)\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m w,loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/miniconda3/envs/MainPy/lib/python3.11/site-packages/numpy/linalg/linalg.py:2326\u001b[39m, in \u001b[36mlstsq\u001b[39m\u001b[34m(a, b, rcond)\u001b[39m\n\u001b[32m   2323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_rhs == \u001b[32m0\u001b[39m:\n\u001b[32m   2324\u001b[39m     \u001b[38;5;66;03m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[32m   2325\u001b[39m     b = zeros(b.shape[:-\u001b[32m2\u001b[39m] + (m, n_rhs + \u001b[32m1\u001b[39m), dtype=b.dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2326\u001b[39m x, resids, rank, s = gufunc(a, b, rcond, signature=signature, extobj=extobj)\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m m == \u001b[32m0\u001b[39m:\n\u001b[32m   2328\u001b[39m     x[...] = \u001b[32m0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X_max = data_preprocessing.build_poly(x_train, 3)\n",
    "initial_w = np.zeros(X_max.shape[1])\n",
    "\n",
    "cross_validation.cross_validation_demo(y=y_train, x=x_train, k_fold=5, lambdas=[0.001], degree=3, initial_w=initial_w, max_iters=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41833652",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 575 is different from 561)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m x_test = np.loadtxt(\u001b[33m'\u001b[39m\u001b[33mx_test_preprocessed.csv\u001b[39m\u001b[33m'\u001b[39m, delimiter=\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m y_train = np.loadtxt(\u001b[33m'\u001b[39m\u001b[33my_train_preprocessed.csv\u001b[39m\u001b[33m'\u001b[39m, delimiter=\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m y_pred = x_test\u001b[38;5;129m@best_ridge_weights\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 575 is different from 561)"
     ]
    }
   ],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')\n",
    "y_pred = x_test@best_ridge_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d68f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cbba3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8658, 575)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1af01490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 561)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74e913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MainPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
