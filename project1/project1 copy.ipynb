{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e6083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'implemented_functions' from '/Users/mpecaut/ML_project1/project1/implemented_functions.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import data_preprocessing\n",
    "import importlib\n",
    "importlib.reload(data_preprocessing)\n",
    "import cross_validation\n",
    "import TEST\n",
    "importlib.reload(TEST)\n",
    "importlib.reload(cross_validation)\n",
    "import implemented_functions\n",
    "importlib.reload(implemented_functions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e42811",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "x_train_raw, x_test_raw,y_train_raw, train_ids, test_ids = load_csv_data('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9001d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n",
      "(109379, 321)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(x_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0f96d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3000000e+01, 1.1000000e+01, 1.1162015e+07, ...,           nan,\n",
       "                  nan, 2.0000000e+00],\n",
       "       [3.3000000e+01, 1.2000000e+01, 1.2152015e+07, ...,           nan,\n",
       "                  nan,           nan],\n",
       "       [2.0000000e+01, 1.0000000e+01, 1.0202015e+07, ..., 1.0000000e+00,\n",
       "        2.0000000e+00, 2.0000000e+00],\n",
       "       ...,\n",
       "       [3.9000000e+01, 1.0000000e+01, 1.0202015e+07, ..., 2.0000000e+00,\n",
       "        2.0000000e+00, 2.0000000e+00],\n",
       "       [3.3000000e+01, 1.2000000e+01, 1.2302015e+07, ...,           nan,\n",
       "                  nan, 2.0000000e+00],\n",
       "       [3.2000000e+01, 9.0000000e+00, 9.1220150e+06, ...,           nan,\n",
       "                  nan, 2.0000000e+00]], shape=(328135, 321))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88380452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat y_train to have 0's instead of -1's\n",
    "y_train_original = y_train_raw.copy()\n",
    "y_train_raw[y_train_raw == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f793521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.4000000e+01,  2.0000000e+00,  2.0820150e+06, ...,\n",
       "         1.0000000e+00,  1.0000000e+00,  2.0000000e+00],\n",
       "       [ 2.7000000e+01,  1.0000000e+00,  1.1920150e+06, ...,\n",
       "        -1.0000000e+01, -1.0000000e+01,  2.0000000e+00],\n",
       "       [ 3.5000000e+01,  5.0000000e+00,  5.2620150e+06, ...,\n",
       "         1.0000000e+00,  1.0000000e+00,  2.0000000e+00],\n",
       "       ...,\n",
       "       [ 9.0000000e+00,  1.1000000e+01,  1.1272015e+07, ...,\n",
       "         9.0000000e+00,  9.0000000e+00, -1.0000000e+01],\n",
       "       [ 1.5000000e+01,  1.2000000e+01,  1.2122015e+07, ...,\n",
       "         1.0000000e+00,  1.0000000e+00,  2.0000000e+00],\n",
       "       [ 4.5000000e+01,  1.2000000e+01,  1.2282015e+07, ...,\n",
       "        -1.0000000e+01, -1.0000000e+01,  2.0000000e+00]],\n",
       "      shape=(109379, 321))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace NaN by a float to treat NaN as a categorical feature\n",
    "#TODO: NAN'S :apagnan -10 or 0 --> SAME BETWEEN TRAIN AND TEST \n",
    "x_test_raw = np.nan_to_num(x_test_raw, nan = -10.0)\n",
    "x_test_raw.shape\n",
    "x_test_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75961310",
   "metadata": {},
   "source": [
    "### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1db0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annoted = data_preprocessing.read_annotated_csv('dataset/data_anotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc22ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mpecaut/ML_project1/project1/data_preprocessing.py:172: RuntimeWarning: invalid value encountered in divide\n",
      "  data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test = data_preprocessing.preprocess_data2(x_train_raw[:50000,:], y_train_raw[:50000], x_test_raw[:50000,:], data_annoted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03843053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaed223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\\nx_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\n",
    "x_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\\ndata_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\n",
    "data_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14361aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('x_train_preprocessed.csv', x_train, delimiter=',')\n",
    "np.savetxt('y_train_preprocessed.csv', y_train, delimiter=',')\n",
    "np.savetxt('x_test_preprocessed.csv', x_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec040d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "404fcaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 576)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfff5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py:140: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w = np.linalg.lstsq(tx,y)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: Loss = 0.03209577896705887\n",
      "Mean Squared Error SGD (gamma=0.01): Loss = [0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.10460163310080063, 0.07674929675650492, 0.05510969595540356, 0.04592840657268578, 0.04592461697787984, 0.047647450453146244, 0.04840684037558661, 0.050707335918181454, 0.05577344593513922, 0.04997650457769179, 0.05375440864871297, 0.046217230162049414, 0.049233421680005364, 0.04753471636636235, 0.04705758883254935, 0.04725311059930179, 0.047679788835154585, 0.048366736445749174, 0.0467584773446901, 0.04642375098896919, 0.04549349827716162, 0.04755884514355169, 0.04681175708961924, 0.047234988527297427, 0.047538788512213, 0.04732329008213579, 0.04617092360163797, 0.046334533946144674, 0.047980887253537795, 0.04483021906156473, 0.04529905142728463, 0.04735922290637097, 0.045938596458818114, 0.044110157735305314, 0.04792366626187106, 0.04761705173302831, 0.047457737986928414, 0.04816393659243638, 0.04858224007359272]\n",
      "Mean Squared Error SGD (gamma=0.1): Loss = [0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 6.666766368507807, 40.300704394097615, 722.5994518755849, 7337.303675398317, 88390.44948323623, 435239.8009681646, 348522.7239198049, 2817457.1835113717, 9490389.648564825, 101711505.74648349, 1295690808.529301, 17212387774.985336, 247120489495.01788, 3669945810827.897, 31322853821779.914, 603596440511603.1, 8224617594962215.0, 6.60522067570623e+16, 1.3023837681890296e+18, 7.90785810373925e+17, 1.0586732847250783e+18, 6.137611470838115e+17, 1.344912473126861e+18, 5.984796645885417e+17]\n",
      "Mean Squared Error SGD (gamma=0.5): Loss = [0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 213.63822377164092, 117445.36317647723, 58459420.94313849, 22744200180.044792, 8415894348399.855, 1217352500822765.5, 5.1741540883372154e+17, 1.2646247517562452e+20, 3.4234919123609243e+22, 1.4105814337162475e+25, 8.331801465062154e+27, 3.439326108213381e+30, 1.1920062275454012e+33, 1.675479997889176e+35, 7.054257137188343e+37, 2.7722661738653344e+40, 1.6347098621997177e+43, 7.362077206641476e+45, 3.0163261440871855e+48, 1.3373445297906488e+51, 7.416889816287389e+53, 3.3670481768344e+56, 1.707953355693134e+59, 7.161231631929445e+61, 2.599243597764065e+64, 2.5907410016243412e+66, 8.765434864257354e+68, 3.3141681301094104e+71, 6.129365559269536e+73, 5.0195498547277946e+76, 2.190871774463083e+79, 1.0962119525843676e+82, 4.077362973365328e+84, 2.5387417282231166e+87, 1.0975991756435943e+90, 3.5298628363037535e+92, 1.5684626622950808e+95, 4.481843645221734e+97, 2.445910820803332e+100, 1.8079917708834243e+103, 3.8397748452409883e+105, 1.480489772452169e+108, 6.46940881345875e+110, 5.195615696949808e+112, 1.2286524798445724e+115, 4.2989956262542904e+117]\n",
      "Mean Squared Error SGD (gamma=1): Loss = [0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 0.04345555555555556, 752.8234605586492, 968494.465135372, 1648046658.7395036, 1682339228779.767, 1546466282188547.5, 2.1498007505633802e+18, 3.313740375629865e+21, 4.1226704014660923e+24, 1.4653916269368088e+28, 4.158440380571474e+31, 1.2778985126693744e+35, 3.2288382575243475e+38, 4.450046839746264e+41, 5.683112514382822e+44, 6.978829183454506e+47, 8.305993750821128e+50, 9.51369340267724e+53, 1.4888209088472606e+57, 2.4207818841513258e+60, 2.431117670875905e+63, 7.850094954278307e+66, 4.325118364761089e+69, 9.122177481610469e+72, 2.14761471828099e+76, 3.970321131961364e+79, 7.333676897115525e+82, 8.047836994957563e+85, 5.925494843895332e+88, 9.19302665415275e+91, 1.0923469912458212e+95, 1.2493478646125468e+98, 2.590727855706754e+101, 1.8966410110929986e+104, 5.0839896785381575e+107, 5.649641935105381e+110, 1.0844991135210177e+114, 2.0648216130204036e+117, 5.1077666342712073e+120, 7.221848647311278e+123, 1.4134025560524932e+127]\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.1): Loss = 0.1706718274799002\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.01): Loss = 0.030086447464880955\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.1): Loss = 0.43980731206675167\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.01): Loss = 0.03605752727990304\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.1): Loss = 2.176460383442984\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.01): Loss = 0.05469078480270288\n",
      "Ridge Regression (alpha=0.001): Loss = 0.07548518964720417\n",
      "Ridge Regression (alpha=0.01): Loss = 0.07753806261584242\n",
      "Ridge Regression (alpha=0.1): Loss = 0.08200100140523187\n",
      "Ridge Regression (alpha=1): Loss = 0.09741718323812881\n",
      "Ridge Regression (alpha=10): Loss = 0.14065078564050496\n",
      "Logistic Regression: Loss = 4.8858844779930795e-05\n",
      "Logistic Regression: Loss = 4.422729764048705e-05\n",
      "Logistic Regression: Loss = 4.091049204160757e-05\n",
      "Logistic Regression: Loss = 3.1463404502987915e-05\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.01): Loss = 0.00010570141918785086\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.01): Loss = 0.0006154164270238566\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.01): Loss = 0.00553276050065175\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.1): Loss = 0.00022740542428916486\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.1): Loss = 0.0018237110072987452\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.1): Loss = 0.013751748879188503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_w = np.zeros(x_train.shape[1])\n",
    "max_iters = 50\n",
    "\n",
    "x_test = x_train[45000:,:]\n",
    "y_test = y_train[45000:]\n",
    "x_train = x_train[:45000,:]\n",
    "y_train = y_train[:45000]\n",
    "\n",
    "\n",
    "w_least_squares, loss_ls = implemented_functions.least_squares(y_train, x_train)\n",
    "print(f\"Least Squares: Loss = {loss_ls}\")\n",
    "\n",
    "best_mse_coef = 0\n",
    "best_mse_loss = np.inf\n",
    "best_mse_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_sgd, loss_sgd = implemented_functions.mean_squared_error_sgd(y_train,  x_train, initial_w, max_iters, gamma)\n",
    "    if loss_sgd[-1] < best_mse_loss:\n",
    "        best_mse_loss = loss_sgd[-1]\n",
    "        best_mse_coef = gamma\n",
    "        best_mse_weights = w_sgd\n",
    "    print(f\"Mean Squared Error SGD (gamma={gamma}): Loss = {loss_sgd}\")\n",
    "\n",
    "best_log_lasso_coef = 0\n",
    "best_log_lasso_loss = np.inf\n",
    "best_log_lasso_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5]:\n",
    "    for lambda_ in [0.1, 0.01]:\n",
    "        w_log_lasso, loss_log_lasso = implemented_functions.reg_logistic_lasso_subgradient(y_train, x_train, lambda_, initial_w, max_iters, gamma)\n",
    "        if loss_log_lasso < best_log_lasso_loss:\n",
    "            best_log_lasso_loss = loss_log_lasso\n",
    "            best_log_lasso_weights = w_log_lasso\n",
    "        print(f\"Regularized Lasso Logistic Regression (gamma={gamma}, lambda={lambda_}): Loss = {loss_log_lasso}\")\n",
    "        \n",
    "best_ridge_coef = 0\n",
    "best_ridge_loss = np.inf\n",
    "best_ridge_weights = None\n",
    "for ridge_coef in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    w_ridge, loss_ridge = implemented_functions.ridge_regression(y_train, x_train, ridge_coef)\n",
    "    if loss_ridge < best_ridge_loss:\n",
    "        best_ridge_loss = loss_ridge\n",
    "        best_ridge_coef = ridge_coef\n",
    "        best_ridge_weights = w_ridge\n",
    "    print(f\"Ridge Regression (alpha={ridge_coef}): Loss = {loss_ridge}\")\n",
    "\n",
    "best_log_gamma = 0\n",
    "best_log_loss = np.inf\n",
    "best_log_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_logistic, loss_logistic = implemented_functions.logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "    if loss_logistic < best_log_loss:\n",
    "        best_log_loss = loss_logistic\n",
    "        best_log_gamma = gamma\n",
    "        best_log_weights = w_logistic\n",
    "    print(f\"Logistic Regression: Loss = {loss_logistic}\")\n",
    "\n",
    "best_log_reg_coef = 0\n",
    "best_log_reg_loss = np.inf\n",
    "best_log_reg_weights = None\n",
    "for gamma in [0.01, 0.1]:\n",
    "    for reg_coef in [0.001, 0.01, 0.1]:\n",
    "        w_reg_logistic, loss_reg_logistic = implemented_functions.reg_logistic_regression(y_train, x_train, reg_coef, initial_w, max_iters, gamma)\n",
    "        if loss_reg_logistic < best_log_reg_loss:\n",
    "            best_log_reg_loss = loss_reg_logistic\n",
    "            best_log_reg_coef = reg_coef\n",
    "            best_log_reg_weights = w_reg_logistic\n",
    "        print(f\"Regularized Logistic Regression (alpha={reg_coef}, gamma={gamma}): Loss = {loss_reg_logistic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dd05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD is 91.64%\n",
      "F1 score SGD is 0.0\n",
      "Accuracy of Least Squares is 91.97999999999999%\n",
      "F1 score Least Squares is 0.12253829321663019\n",
      "Accuracy of Ridge is 76.58%\n",
      "F1 score Ridge is 0.36185286103542236\n",
      "[0.18878668 0.01735786 0.05975914 ... 0.00851406 0.44185317 0.07404378]\n",
      "Accuracy of Logistic is 90.66%\n",
      "F1 score Logistic is 0.33946251768033947\n",
      "[0.09847767 0.09479492 0.08190276 ... 0.08479488 0.15641836 0.11541087]\n",
      "Accuracy of Regularized Logistic is 91.64%\n",
      "F1 score Regularized Logistic is 0.0\n",
      "[0.11006322 0.10422189 0.09222174 ... 0.09536845 0.17423382 0.12823048]\n",
      "Accuracy of Regularized Lasso is 91.64%\n",
      "F1 score Regularized Lasso is 0.0\n",
      "Accuracy of SGD is 91.64%\n",
      "F1 score SGD is 0.0\n",
      "Accuracy of Least Squares is 87.52%\n",
      "F1 score Least Squares is 0.007142857142857143\n",
      "Accuracy of Ridge is 52.76%\n",
      "F1 score Ridge is 0.49810366624525915\n",
      "[0.18878668 0.01735786 0.05975914 ... 0.00851406 0.44185317 0.07404378]\n",
      "Accuracy of Logistic is 83.04%\n",
      "F1 score Logistic is 0.32941176470588235\n",
      "[0.09847767 0.09479492 0.08190276 ... 0.08479488 0.15641836 0.11541087]\n",
      "Accuracy of Regularized Logistic is 91.64%\n",
      "F1 score Regularized Logistic is 0.0\n",
      "[0.11006322 0.10422189 0.09222174 ... 0.09536845 0.17423382 0.12823048]\n",
      "Accuracy of Regularized Lasso is 91.64%\n",
      "F1 score Regularized Lasso is 0.0\n",
      "Accuracy of SGD is 91.64%\n",
      "F1 score SGD is 0.0\n",
      "Accuracy of Least Squares is 91.64%\n",
      "F1 score Least Squares is 0.004761904761904762\n",
      "Accuracy of Ridge is 88.12%\n",
      "F1 score Ridge is 0.39878542510121456\n",
      "[0.18878668 0.01735786 0.05975914 ... 0.00851406 0.44185317 0.07404378]\n",
      "Accuracy of Logistic is 91.96%\n",
      "F1 score Logistic is 0.2178988326848249\n",
      "[0.09847767 0.09479492 0.08190276 ... 0.08479488 0.15641836 0.11541087]\n",
      "Accuracy of Regularized Logistic is 91.64%\n",
      "F1 score Regularized Logistic is 0.0\n",
      "[0.11006322 0.10422189 0.09222174 ... 0.09536845 0.17423382 0.12823048]\n",
      "Accuracy of Regularized Lasso is 91.64%\n",
      "F1 score Regularized Lasso is 0.0\n",
      "Accuracy of Ridge is 52.76%\n",
      "-----Ridge: F1 score Ridge at threshold 0.3 is 0.49810366624525915\n",
      "Accuracy of Ridge is 76.58%\n",
      "-----Ridge: F1 score Ridge at threshold 0.5 is 0.36185286103542236\n",
      "Accuracy of Ridge is 88.12%\n",
      "-----Ridge: F1 score Ridge at threshold 0.7 is 0.39878542510121456\n",
      "Accuracy of Ridge is 91.16%\n",
      "-----Ridge: F1 score Ridge at threshold 0.8 is 0.37746478873239436\n",
      "Accuracy of Ridge is 91.78%\n",
      "-----Ridge: F1 score Ridge at threshold 0.9 is 0.26475849731663686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import implemented_functions\n",
    "\n",
    "def test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.5):\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, w_sgd, \"SGD\", threshold)\n",
    "    print(f\"F1 score SGD is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, w_least_squares, \"Least Squares\", threshold)\n",
    "    print(f\"F1 score Least Squares is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_ridge_weights, \"Ridge\", threshold)\n",
    "    print(f\"F1 score Ridge is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_weights, \"Logistic\", threshold)\n",
    "    print(f\"F1 score Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_reg_weights, \"Regularized Logistic\", threshold)\n",
    "    print(f\"F1 score Regularized Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_lasso_weights, \"Regularized Lasso\", threshold)\n",
    "    print(f\"F1 score Regularized Lasso is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    return y_pred\n",
    "\n",
    "def test_thresholds(x_test, y_test, weights, method):\n",
    "    for threshold in [0.3, 0.5, 0.7, 0.8, 0.9]:\n",
    "        accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, weights, method, threshold)\n",
    "        print(f\"-----{method}: F1 score {method} at threshold {threshold} is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.5)\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.3)\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.7)\n",
    "\n",
    "test_thresholds(x_test, y_test, best_ridge_weights, \"Ridge\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89041a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = np.sum(y_test == 1)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41833652",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 575 is different from 561)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m x_test = np.loadtxt(\u001b[33m'\u001b[39m\u001b[33mx_test_preprocessed.csv\u001b[39m\u001b[33m'\u001b[39m, delimiter=\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m y_train = np.loadtxt(\u001b[33m'\u001b[39m\u001b[33my_train_preprocessed.csv\u001b[39m\u001b[33m'\u001b[39m, delimiter=\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m y_pred = x_test\u001b[38;5;129m@best_ridge_weights\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 575 is different from 561)"
     ]
    }
   ],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')\n",
    "y_pred = x_test@best_ridge_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbba3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8658, 575)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af01490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 561)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74e913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empiricalmethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
