{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87e6083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'implemented_functions' from '/Users/christophersoriano/Library/Mobile Documents/com~apple~CloudDocs/Mac/Epfl/Master/MA3/Machine Learning/ML_project1/project1/implemented_functions.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import data_preprocessing\n",
    "import importlib\n",
    "importlib.reload(data_preprocessing)\n",
    "import cross_validation\n",
    "import TEST\n",
    "importlib.reload(TEST)\n",
    "importlib.reload(cross_validation)\n",
    "import implemented_functions\n",
    "importlib.reload(implemented_functions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e42811",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c76a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "x_train_raw, x_test_raw,y_train_raw, train_ids, test_ids = load_csv_data('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9001d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n",
      "(109379, 321)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_raw.shape)\n",
    "print(x_test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88380452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat y_train to have 0's instead of -1's\n",
    "y_train_original = y_train_raw.copy()\n",
    "y_train_raw[y_train_raw == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f793521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace NaN by a float to treat NaN as a categorical feature\n",
    "x_test_raw = np.nan_to_num(x_test_raw, nan = -10.0)\n",
    "x_test_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75961310",
   "metadata": {},
   "source": [
    "### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1db0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_annoted = data_preprocessing.read_annotated_csv('dataset/data_anotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc22ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = data_preprocessing.preprocess_data2(x_train_raw[:50000,:], y_train_raw[:50000], x_test_raw[:50000,:], data_annoted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852ad8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03843053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaed223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\\nx_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x_train_filtered = data_preprocessing.remove_useless(x_train_raw, data_annoted)\n",
    "x_test_filtered = data_preprocessing.remove_useless(x_test_raw, data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84a8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\\ndata_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_train = data_preprocessing.clean_data(x_train_filtered[:100000,:], data_annoted)\n",
    "data_test = data_preprocessing.clean_data(x_test_filtered[:100000,:], data_annoted)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14361aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('x_train_preprocessed.csv', x_train, delimiter=',')\n",
    "np.savetxt('y_train_preprocessed.csv', y_train, delimiter=',')\n",
    "np.savetxt('x_test_preprocessed.csv', x_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec040d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfff5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: Loss = 0.02937233535573916\n",
      "Mean Squared Error SGD (gamma=0.01): Loss = [0.043428571428571434, 0.043428571428571434, 0.09046186662122753, 0.054125165634448066, 0.04229686038454425, 0.04072663567268243, 0.04088354581770833, 0.041993604620169996, 0.0427165517232729, 0.04379471077892396, 0.043324995087639595, 0.04434855794550884, 0.04376844345222379, 0.04263595874806054, 0.04307930548847357, 0.04215898039417133, 0.04282388797614339, 0.04148889137845025, 0.047983136937909086, 0.046373539241470245, 0.04389427699455997, 0.042515888285590886, 0.10736085908804023, 0.047473174719232306, 0.03910224560871096, 0.03833094834263337, 0.03857217604386013, 0.0383722054902626, 0.039311660111795856, 0.038718794489773785, 0.038518564963564296, 0.03997660506248597, 0.03989963397011998, 0.03980521839749573, 0.044462524233832346, 0.049553049980584005, 0.04608804415504674, 0.047150460705441745, 0.04211324078800699, 0.04332384474804474, 0.045247887436550484, 0.04043690153642787, 0.039547753895686884, 0.04108767107524549, 0.05458989668651179, 0.036768910975236505, 0.037219278197812955, 0.036807965663864205, 0.038771110157015176, 0.03729550637549447]\n",
      "Mean Squared Error SGD (gamma=0.1): Loss = [0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 6.616986957539634, 45.32144429985197, 167.17762564077566, 1832.0273755033459, 16256.939404794475, 127571.65390819308, 1829607.499549413, 20092597.133223437, 185878376.80032492, 1341821553.0952516, 12670595230.745121, 241698713496.41446, 2514016209144.405, 9859724626884.04, 36415985203244.1, 6212288341562.099, 117058630579259.45, 1025114633273420.8, 1.0147590176535792e+16, 2.221933178554101e+17, 3.5811172307877535e+18, 1.5240936094203783e+19, 1.6726428418048085e+20, 8.490732691946738e+20, 2.7669806367621844e+21, 8.286625414248355e+22, 4.5066749235930226e+23, 2.537294492403067e+24, 5.556573032266076e+25, 6.75879396585933e+26, 1.6728234614676702e+27, 3.9342493786376252e+28, 1.3070893210059085e+29, 2.948742526517214e+30, 1.8193457022409595e+30, 2.675909173294686e+30, 7.3441076790515525e+31]\n",
      "Mean Squared Error SGD (gamma=0.5): Loss = [0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 0.043428571428571434, 238.63553580274143, 101125.9722711484, 33197583.408896305, 15207956638.26252, 7688615479644.962, 695592484399145.5, 3.683140635913775e+17, 9.965044855649862e+19, 4.2147506074999885e+22, 2.6262921650162686e+25, 1.1135983244648463e+28, 1.531364536719412e+30, 2.2532959269846997e+32, 1.1318209627834427e+35, 3.4738830872736566e+37, 9.021199449546568e+39, 6.22237867632715e+42, 2.278658992337766e+45, 1.0759135385993002e+48, 4.47390197294014e+50, 2.1183927052236564e+53, 9.314534215275706e+55, 4.7827213692835216e+58, 1.6370211081155134e+61, 4.3282095108476386e+63, 2.5044432767077642e+66, 6.649144368571379e+68, 3.910120003099952e+71, 1.5144865512475733e+74, 5.58127238244137e+76, 5.199836490257065e+78, 1.368865403940304e+81, 6.258093866110836e+83, 2.5430454525547993e+86, 1.8848083806406436e+89, 5.702692000262923e+91, 2.7828434901228184e+94, 7.557622357780636e+96, 4.680303650737062e+99, 2.2581507716298966e+102, 7.336438816193616e+104, 4.047452306117373e+107, 1.5886502864777542e+110]\n",
      "Mean Squared Error SGD (gamma=1): Loss = [0.043428571428571434, 0.043428571428571434, 1066.0743409836011, 1859301.4264143943, 811815537.6233945, 1598532440181.0447, 4614823784441144.0, 9.267557409318269e+18, 1.082712987081759e+22, 2.6930371041060164e+25, 2.7820434585915285e+28, 3.832980737927497e+31, 2.5142174458836897e+34, 6.35412645189155e+37, 1.2059822064914145e+41, 1.6854949673513212e+44, 4.533001505934224e+47, 5.983078716730514e+50, 1.2453948112233593e+54, 3.566783696917123e+57, 6.314906795173133e+60, 6.853106651581761e+63, 1.5978409423701715e+67, 6.529144830198002e+70, 3.535115672822819e+73, 5.870174946138329e+76, 6.366071913019655e+79, 1.1320467499900368e+83, 1.9897514292298718e+86, 4.2315980730098246e+89, 7.619020012115314e+92, 1.3596691152538746e+96, 2.3708315916500565e+99, 4.593072838089718e+102, 5.587966985212518e+105, 1.3209494737757127e+109, 2.366609530312856e+112, 3.677484412612596e+115, 3.372066360324637e+118, 7.455899947021977e+121, 1.3461981313357231e+125, 2.44765047084607e+128, 2.4004832757608477e+131, 4.9438077826610785e+134, 1.1756180889326055e+138, 1.9358963159415824e+141, 4.4890017289348416e+144, 1.0409294181852961e+148, 3.5607324433931396e+151, 4.088831924515576e+154]\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.1): Loss = 0.17008164659144506\n",
      "Regularized Lasso Logistic Regression (gamma=0.01, lambda=0.01): Loss = 0.030285895772201605\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.1): Loss = 0.39796038911178105\n",
      "Regularized Lasso Logistic Regression (gamma=0.1, lambda=0.01): Loss = 0.037095536292495276\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.1): Loss = 2.0264056835161215\n",
      "Regularized Lasso Logistic Regression (gamma=0.5, lambda=0.01): Loss = 0.05587711254387022\n",
      "Ridge Regression (alpha=0.001): Loss = 3.2663253770163014e-05\n",
      "Ridge Regression (alpha=0.01): Loss = 5.1166706484533585e-05\n",
      "Ridge Regression (alpha=0.1): Loss = 6.757204617905083e-05\n",
      "Ridge Regression (alpha=1): Loss = 7.10036001012344e-05\n",
      "Ridge Regression (alpha=10): Loss = 7.138563538035831e-05\n",
      "Logistic Regression: Loss = 0.00031165011565729457\n",
      "Logistic Regression: Loss = 0.00027497469333520824\n",
      "Logistic Regression: Loss = 0.0002502177462931133\n",
      "Logistic Regression: Loss = 0.00017878752041899668\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.01): Loss = 0.0003688947035642222\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.01): Loss = 0.0008822093177125697\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.01): Loss = 0.00583377246828111\n",
      "Regularized Logistic Regression (alpha=1, gamma=0.01): Loss = 0.041342299672217475\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.1): Loss = 0.00047331541752088004\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.1): Loss = 0.0022000540127910086\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.1): Loss = 0.014976394633668252\n",
      "Regularized Logistic Regression (alpha=1, gamma=0.1): Loss = 0.04360633568068781\n",
      "Regularized Logistic Regression (alpha=0.001, gamma=0.5): Loss = 0.0008209491153266667\n",
      "Regularized Logistic Regression (alpha=0.01, gamma=0.5): Loss = 0.005239932494903371\n",
      "Regularized Logistic Regression (alpha=0.1, gamma=0.5): Loss = 0.02093633818823436\n",
      "Regularized Logistic Regression (alpha=1, gamma=0.5): Loss = 0.10363966922191822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_w = np.zeros(x_train.shape[1])\n",
    "max_iters = 50\n",
    "\n",
    "x_test = x_train[7000:,:]\n",
    "y_test = y_train[7000:]\n",
    "x_train = x_train[:7000,:]\n",
    "y_train = y_train[:7000]\n",
    "\n",
    "\n",
    "w_least_squares, loss_ls = implemented_functions.least_squares(y_train, x_train)\n",
    "print(f\"Least Squares: Loss = {loss_ls}\")\n",
    "\n",
    "best_mse_coef = 0\n",
    "best_mse_loss = np.inf\n",
    "best_mse_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_sgd, loss_sgd = implemented_functions.mean_squared_error_sgd(y_train,  x_train, initial_w, max_iters, gamma)\n",
    "    if loss_sgd[-1] < best_mse_loss:\n",
    "        best_mse_loss = loss_sgd[-1]\n",
    "        best_mse_coef = gamma\n",
    "        best_mse_weights = w_sgd\n",
    "    print(f\"Mean Squared Error SGD (gamma={gamma}): Loss = {loss_sgd}\")\n",
    "\n",
    "best_log_lasso_coef = 0\n",
    "best_log_lasso_loss = np.inf\n",
    "best_log_lasso_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5]:\n",
    "    for lambda_ in [0.1, 0.01]:\n",
    "        w_log_lasso, loss_log_lasso = implemented_functions.reg_logistic_lasso_subgradient(y_train, x_train, lambda_, initial_w, max_iters, gamma)\n",
    "        if loss_log_lasso < best_log_lasso_loss:\n",
    "            best_log_lasso_loss = loss_log_lasso\n",
    "            best_log_lasso_weights = w_log_lasso\n",
    "        print(f\"Regularized Lasso Logistic Regression (gamma={gamma}, lambda={lambda_}): Loss = {loss_log_lasso}\")\n",
    "        \n",
    "best_ridge_coef = 0\n",
    "best_ridge_loss = np.inf\n",
    "best_ridge_weights = None\n",
    "for ridge_coef in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    w_ridge, loss_ridge = implemented_functions.ridge_regression(y_train, x_train, ridge_coef)\n",
    "    if loss_ridge < best_ridge_loss:\n",
    "        best_ridge_loss = loss_ridge\n",
    "        best_ridge_coef = ridge_coef\n",
    "        best_ridge_weights = w_ridge\n",
    "    print(f\"Ridge Regression (alpha={ridge_coef}): Loss = {loss_ridge}\")\n",
    "\n",
    "best_log_gamma = 0\n",
    "best_log_loss = np.inf\n",
    "best_log_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5, 1]:\n",
    "    w_logistic, loss_logistic = implemented_functions.logistic_regression(y_train, x_train, initial_w, max_iters, gamma)\n",
    "    if loss_logistic < best_log_loss:\n",
    "        best_log_loss = loss_logistic\n",
    "        best_log_gamma = gamma\n",
    "        best_log_weights = w_logistic\n",
    "    print(f\"Logistic Regression: Loss = {loss_logistic}\")\n",
    "\n",
    "best_log_reg_coef = 0\n",
    "best_log_reg_loss = np.inf\n",
    "best_log_reg_weights = None\n",
    "for gamma in [0.01, 0.1, 0.5]:\n",
    "    for reg_coef in [0.001, 0.01, 0.1, 1]:\n",
    "        w_reg_logistic, loss_reg_logistic = implemented_functions.reg_logistic_regression(y_train, x_train, reg_coef, initial_w, max_iters, gamma)\n",
    "        if loss_reg_logistic < best_log_reg_loss:\n",
    "            best_log_reg_loss = loss_reg_logistic\n",
    "            best_log_reg_coef = reg_coef\n",
    "            best_log_reg_weights = w_reg_logistic\n",
    "        print(f\"Regularized Logistic Regression (alpha={reg_coef}, gamma={gamma}): Loss = {loss_reg_logistic}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5535ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.07318898540649"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train@best_log_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5dd05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SGD is 91.34651162790698%\n",
      "F1 score SGD is 0.0\n",
      "Accuracy of Least Squares is 91.24651162790698%\n",
      "F1 score Least Squares is 0.15718763994626064\n",
      "Accuracy of Ridge is 80.04883720930232%\n",
      "F1 score Ridge is 0.3517944843218738\n",
      "Accuracy of Logistic is 89.26046511627908%\n",
      "F1 score Logistic is 0.37391540130151846\n",
      "Accuracy of Regularized Logistic is 91.34651162790698%\n",
      "F1 score Regularized Logistic is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import implemented_functions\n",
    "\n",
    "def test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.5):\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, w_sgd, \"SGD\", threshold)\n",
    "    print(f\"F1 score SGD is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, w_least_squares, \"Least Squares\", threshold)\n",
    "    print(f\"F1 score Least Squares is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_ridge_weights, \"Ridge\", threshold)\n",
    "    print(f\"F1 score Ridge is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_weights, \"Logistic\", threshold)\n",
    "    print(f\"F1 score Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    accuracy, y_pred = implemented_functions.compute_accuracy(y_test, x_test, best_log_reg_weights, \"Regularized Logistic\", threshold)\n",
    "    print(f\"F1 score Regularized Logistic is {implemented_functions.compute_f1_score(y_test, y_pred)}\")\n",
    "    return y_pred\n",
    "\n",
    "test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.5)\n",
    "#test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=0.3)\n",
    "#test_methods(x_test, y_test, w_sgd, w_least_squares, best_ridge_weights, best_log_weights, best_log_reg_weights, threshold=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89041a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = np.sum(y_test == 1)\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41833652",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 575 is different from 561)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m x_test = np.loadtxt(\u001b[33m'\u001b[39m\u001b[33mx_test_preprocessed.csv\u001b[39m\u001b[33m'\u001b[39m, delimiter=\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m y_train = np.loadtxt(\u001b[33m'\u001b[39m\u001b[33my_train_preprocessed.csv\u001b[39m\u001b[33m'\u001b[39m, delimiter=\u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m y_pred = x_test\u001b[38;5;129m@best_ridge_weights\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 575 is different from 561)"
     ]
    }
   ],
   "source": [
    "x_train = np.loadtxt('x_train_preprocessed.csv', delimiter=',')\n",
    "x_test = np.loadtxt('x_test_preprocessed.csv', delimiter=',')\n",
    "y_train = np.loadtxt('y_train_preprocessed.csv', delimiter=',')\n",
    "y_pred = x_test@best_ridge_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbba3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8658, 575)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af01490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 561)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74e913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MainPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
